{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ComfyUI\u793e\u533a\u7248 \u514d\u8d23\u58f0\u660e\uff1a \u672c\u670d\u52a1\u7531\u7b2c\u4e09\u65b9\u63d0\u4f9b\uff0c\u6211\u4eec\u5c3d\u529b\u786e\u4fdd\u5176\u5b89\u5168\u6027\u3001\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u5176\u5b8c\u5168\u514d\u4e8e\u6545\u969c\u3001\u4e2d\u65ad\u3001\u9519\u8bef\u6216\u653b\u51fb\u3002\u56e0\u6b64\uff0c\u672c\u516c\u53f8\u5728\u6b64\u58f0\u660e\uff1a\u5bf9\u4e8e\u672c\u670d\u52a1\u7684\u5185\u5bb9\u3001\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u53ef\u9760\u6027\u3001\u9002\u7528\u6027\u4ee5\u53ca\u53ca\u65f6\u6027\u4e0d\u4f5c\u4efb\u4f55\u9648\u8ff0\u3001\u4fdd\u8bc1\u6216\u627f\u8bfa\uff0c\u4e0d\u5bf9\u60a8\u4f7f\u7528\u672c\u670d\u52a1\u6240\u4ea7\u751f\u7684\u4efb\u4f55\u76f4\u63a5\u6216\u95f4\u63a5\u7684\u635f\u5931\u6216\u635f\u5bb3\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff1b\u5bf9\u4e8e\u60a8\u901a\u8fc7\u672c\u670d\u52a1\u8bbf\u95ee\u7684\u7b2c\u4e09\u65b9\u7f51\u7ad9\u3001\u5e94\u7528\u7a0b\u5e8f\u3001\u4ea7\u54c1\u548c\u670d\u52a1\uff0c\u4e0d\u5bf9\u5176\u5185\u5bb9\u3001\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u53ef\u9760\u6027\u3001\u9002\u7528\u6027\u4ee5\u53ca\u53ca\u65f6\u6027\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u60a8\u5e94\u81ea\u884c\u627f\u62c5\u4f7f\u7528\u540e\u679c\u4ea7\u751f\u7684\u98ce\u9669\u548c\u8d23\u4efb\uff1b\u5bf9\u4e8e\u56e0\u60a8\u4f7f\u7528\u672c\u670d\u52a1\u800c\u4ea7\u751f\u7684\u4efb\u4f55\u635f\u5931\u3001\u635f\u5bb3\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u76f4\u63a5\u635f\u5931\u3001\u95f4\u63a5\u635f\u5931\u3001\u5229\u6da6\u635f\u5931\u3001\u5546\u8a89\u635f\u5931\u3001\u6570\u636e\u635f\u5931\u6216\u5176\u4ed6\u7ecf\u6d4e\u635f\u5931\uff0c\u4e0d\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u5373\u4f7f\u672c\u516c\u53f8\u4e8b\u5148\u5df2\u88ab\u544a\u77e5\u53ef\u80fd\u5b58\u5728\u6b64\u7c7b\u635f\u5931\u6216\u635f\u5bb3\u7684\u53ef\u80fd\u6027\uff1b\u6211\u4eec\u4fdd\u7559\u4e0d\u65f6\u4fee\u6539\u672c\u58f0\u660e\u7684\u6743\u5229\uff0c\u56e0\u6b64\u8bf7\u60a8\u5728\u4f7f\u7528\u672c\u670d\u52a1\u524d\u5b9a\u671f\u68c0\u67e5\u672c\u58f0\u660e\u3002\u5982\u679c\u60a8\u5bf9\u672c\u58f0\u660e\u6216\u672c\u670d\u52a1\u5b58\u5728\u4efb\u4f55\u95ee\u9898\u6216\u7591\u95ee\uff0c\u8bf7\u8054\u7cfb\u6211\u4eec\u3002 \u6982\u8ff0 ComfyUI\u662f \u6700\u5f3a\u5927\u7684\u5f00\u6e90\u8282\u70b9\u5f0f\u751f\u6210\u5f0fAI\u5e94\u7528\uff0c\u652f\u6301\u521b\u5efa\u56fe\u50cf\u3001\u89c6\u9891\u53ca\u97f3\u9891\u5185\u5bb9\u3002\u4f9d\u6258\u524d\u6cbf\u5f00\u6e90\u6a21\u578b\u53ef\u5b9e\u73b0\u89c6\u9891\u4e0e\u56fe\u50cf\u751f\u6210\u3002 \u4f9d\u636e\u5b98\u65b9\u6587\u6863\uff0cComfyUI\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a + \u8282\u70b9/\u56fe\u5f62/\u6d41\u7a0b\u56fe\u754c\u9762\uff0c\u7528\u4e8e\u5b9e\u9a8c\u548c\u521b\u5efa\u590d\u6742\u7684\u7a33\u5b9a\u6269\u6563\u5de5\u4f5c\u6d41\u7a0b\uff0c\u65e0\u9700\u7f16\u5199\u4efb\u4f55\u4ee3\u7801\u3002 + \u5b8c\u5168\u652f\u6301 SD1.x\u3001SD2.x \u548c SDXL + \u5f02\u6b65\u961f\u5217\u7cfb\u7edf + \u591a\u9879\u4f18\u5316 \u53ea\u91cd\u65b0\u6267\u884c\u5de5\u4f5c\u6d41\u4e2d\u5728\u4e24\u6b21\u6267\u884c\u4e4b\u95f4\u53d1\u751f\u53d8\u5316\u7684\u90e8\u5206\u3002 + \u547d\u4ee4\u884c\u9009\u9879\uff1a--lowvram \u53ef\u4f7f\u5176\u5728 3GB \u5185\u5b58\u4ee5\u4e0b\u7684 GPU \u4e0a\u8fd0\u884c\uff08\u5728\u4f4e\u5185\u5b58\u7684 GPU \u4e0a\u81ea\u52a8\u542f\u7528\uff09 + \u5373\u4f7f\u6ca1\u6709 GPU \u4e5f\u80fd\u4f7f\u7528\uff1a --cpu\uff08\u6162\u901f\uff09 + \u53ef\u52a0\u8f7d ckpt\u3001safetensors \u548c diffusers \u6a21\u578b/\u68c0\u67e5\u70b9\u3002\u72ec\u7acb\u7684 VAE \u548c CLIP \u6a21\u578b\u3002 + \u5d4c\u5165/\u6587\u672c\u53cd\u6f14 + Loras \uff08\u5e38\u89c4\u3001locon \u548c loha\uff09 + \u8d85\u7f51\u7edc + \u4ece\u751f\u6210\u7684 PNG \u6587\u4ef6\u52a0\u8f7d\u5b8c\u6574\u7684\u5de5\u4f5c\u6d41\uff08\u542b\u79cd\u5b50 + \u4ee5 Json \u6587\u4ef6\u4fdd\u5b58/\u52a0\u8f7d\u5de5\u4f5c\u6d41\u3002 + \u8282\u70b9\u754c\u9762\u53ef\u7528\u4e8e\u521b\u5efa\u590d\u6742\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5982 \"Hires fix \"\u6216\u66f4\u9ad8\u7ea7\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002 + \u533a\u57df\u5408\u6210 + \u4f7f\u7528\u5e38\u89c4\u548c\u5185\u7ed8\u6a21\u578b\u8fdb\u884c\u5185\u7ed8\u3002 + \u63a7\u5236\u7f51\u7edc\u548c T2I \u9002\u914d\u5668 + \u5347\u7ea7\u6a21\u578b\uff08ESRGAN\u3001ESRGAN \u53d8\u4f53\u3001SwinIR\u3001Swin2SR \u7b49\uff09 + unCLIP \u6a21\u578b + GLIGEN + \u6a21\u578b\u5408\u5e76 + \u4f7f\u7528 TAESD \u8fdb\u884c\u6f5c\u4f0f\u9884\u89c8 + \u542f\u52a8\u901f\u5ea6\u6781\u5feb\u3002 + \u5b8c\u5168\u79bb\u7ebf\u5de5\u4f5c\uff1a\u4e0d\u4f1a\u4e0b\u8f7d\u4efb\u4f55\u4e1c\u897f\u3002 + \u914d\u7f6e\u6587\u4ef6\u53ef\u8bbe\u7f6e\u6a21\u578b\u7684\u641c\u7d22\u8def\u5f84\u3002 \u524d\u63d0\u6761\u4ef6 \u90e8\u7f72ComfyUI\u793e\u533a\u7248\u670d\u52a1\u5b9e\u4f8b\uff0c\u9700\u8981\u5bf9\u90e8\u5206\u963f\u91cc\u4e91\u8d44\u6e90\u8fdb\u884c\u8bbf\u95ee\u548c\u521b\u5efa\u64cd\u4f5c\u3002\u56e0\u6b64\u60a8\u7684\u8d26\u53f7\u9700\u8981\u5305\u542b\u5982\u4e0b\u8d44\u6e90\u7684\u6743\u9650\u3002 \u8bf4\u660e \uff1a\u5f53\u60a8\u7684\u8d26\u53f7\u662fRAM\u8d26\u53f7\u65f6\uff0c\u624d\u9700\u8981\u6dfb\u52a0\u6b64\u6743\u9650\u3002 \u6743\u9650\u7b56\u7565\u540d\u79f0 \u5907\u6ce8 AliyunECSFullAccess \u7ba1\u7406\u4e91\u670d\u52a1\u5668\u670d\u52a1\uff08ECS\uff09\u7684\u6743\u9650 AliyunVPCFullAccess \u7ba1\u7406\u4e13\u6709\u7f51\u7edc\uff08VPC\uff09\u7684\u6743\u9650 AliyunROSFullAccess \u7ba1\u7406\u8d44\u6e90\u7f16\u6392\u670d\u52a1\uff08ROS\uff09\u7684\u6743\u9650 AliyunCSFullAccess \u7ba1\u7406\u5bb9\u5668\u670d\u52a1\uff08CS\uff09\u7684\u6743\u9650 AliyunComputeNestUserFullAccess \u7ba1\u7406\u8ba1\u7b97\u5de2\u670d\u52a1\uff08ComputeNest\uff09\u7684\u7528\u6237\u4fa7\u6743\u9650 AliyunOSSFullAccess \u7ba1\u7406\u7f51\u7edc\u5bf9\u8c61\u5b58\u50a8\u670d\u52a1\uff08OSS\uff09\u7684\u6743\u9650 \u8ba1\u8d39\u8bf4\u660e ACS\u7248\u672c\u8d39\u7528 \u672c\u670d\u52a1\u5728\u963f\u91cc\u4e91\u4e0a\u7684\u8d39\u7528\u4e3b\u8981\u6d89\u53ca\uff1a * ACS\u8d39\u7528 * \u8df3\u677f\u673aECS\u8d39\u7528 * \u8bf4\u660e\uff1a\u8be5ECS\u7528\u4e8e\u90e8\u7f72\u548c\u7ba1\u7406K8S\u96c6\u7fa4\uff0c/root\u76ee\u5f55\u4e2d\u4fdd\u5b58\u4e86\u90e8\u7f72\u6240\u7528\u5230\u7684K8S Yaml\u8d44\u6e90\u6587\u4ef6\uff0c\u540e\u671f\u9700\u8981\u4fee\u6539\u4e86\u53c2\u6570\u91cd\u65b0\u90e8\u7f72\u53ef\u4ee5\u76f4\u63a5\u5728\u8be5\u57fa\u7840\u4e0a\u4fee\u6539\u540e\u91cd\u65b0\u6267\u884ckubectl apply\u3002 \u90e8\u7f72\u5b8c\u6210\u5982\u4e0d\u9700\u8981\u4e5f\u53ef\u81ea\u884c\u91ca\u653e\u3002 * OSS\u8d39\u7528 \u8ba1\u8d39\u65b9\u5f0f\uff1a\u6309\u91cf\u4ed8\u8d39\uff08\u5c0f\u65f6\uff09\u6216\u5305\u5e74\u5305\u6708 \u9884\u4f30\u8d39\u7528\u5728\u521b\u5efa\u5b9e\u4f8b\u65f6\u53ef\u5b9e\u65f6\u770b\u5230\u3002 \u793e\u533a\u7248\u8d39\u7528 \u793e\u533a\u7248\u5728\u8ba1\u7b97\u5de2\u90e8\u7f72\u7684\u8d39\u7528\u4e3b\u8981\u6d89\u53ca\uff1a + \u6240\u9009vCPU\u4e0e\u5185\u5b58\u89c4\u683c + \u7cfb\u7edf\u76d8\u7c7b\u578b\u53ca\u5bb9\u91cf + \u516c\u7f51\u5e26\u5bbd \u6574\u4f53\u67b6\u6784 \u90e8\u7f72\u6d41\u7a0b ACS\u7248\u672c\u90e8\u7f72 \u5355\u51fb \u90e8\u7f72\u94fe\u63a5 \u3002\u6839\u636e\u754c\u9762\u63d0\u793a\u586b\u5199\u53c2\u6570\uff0c\u53ef\u4ee5\u770b\u5230\u5bf9\u5e94\u8be2\u4ef7\u660e\u7ec6\uff0c\u786e\u8ba4\u53c2\u6570\u540e\u70b9\u51fb \u4e0b\u4e00\u6b65\uff1a\u786e\u8ba4\u8ba2\u5355 \u3002 \u70b9\u51fb \u4e0b\u4e00\u6b65\uff1a\u786e\u8ba4\u8ba2\u5355 \u540e\u53ef\u4ee5\u4e5f\u770b\u5230\u4ef7\u683c\u9884\u89c8\uff0c\u968f\u540e\u70b9\u51fb \u7acb\u5373\u90e8\u7f72 \uff0c\u7b49\u5f85\u90e8\u7f72\u5b8c\u6210\u3002 \u7b49\u5f85\u90e8\u7f72\u5b8c\u6210\u540e\u5c31\u53ef\u4ee5\u5f00\u59cb\u4f7f\u7528\u670d\u52a1\u3002 ECS\u793e\u533a\u7248\u90e8\u7f72 \u8bbf\u95ee\u8ba1\u7b97\u5de2 \u90e8\u7f72\u94fe\u63a5 \uff0c\u6309\u63d0\u793a\u586b\u5199\u90e8\u7f72\u53c2\u6570 \u586b\u5199\u5b9e\u4f8b\u53c2\u6570 \uff0c\u9009\u62e9\u4f60\u60f3\u8d2d\u4e70\u7684\u65b9\u5f0f\u548c\u5b9e\u4f8b\u7c7b\u578b\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u60f3\u8981\u4f7f\u7528\u56fe\u751f\u89c6\u9891\u529f\u80fd\uff0c\u4e3a\u4e86\u964d\u4f4e\u7206RAM\u5185\u5b58\u7684\u53ef\u80fd\uff0c\u8bf7\u9009\u62e960G\u4ee5\u4e0a\u7684\u5185\u5b58\u89c4\u683c+A10\u4ee5\u4e0a\u7684\u663e\u5361\u89c4\u683c\u3002 \u6839\u636e\u9700\u6c42\u9009\u62e9\u65b0\u5efa\u4e13\u7528\u7f51\u7edc\u6216\u76f4\u63a5\u4f7f\u7528\u5df2\u6709\u7684\u4e13\u6709\u7f51\u7edc\u3002\u586b\u5199\u53ef\u7528\u533a\u548c\u7f51\u7edc\u53c2\u6570 \u70b9\u51fb\u7acb\u5373\u521b\u5efa\uff0c\u7b49\u5f85\u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u5b8c\u6210 \u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u5b8c\u6210\u540e\uff0c\u70b9\u51fb\u5b9e\u4f8bID\u8fdb\u5165\u5230\u8be6\u60c5\u754c\u9762 \u8bbf\u95ee\u670d\u52a1\u5b9e\u4f8b\u7684\u4f7f\u7528URL\uff0c\u8fd9\u91cc\u6211\u4eec\u91c7\u7528\u5b89\u5168\u4ee3\u7406\u76f4\u63a5\u8bbf\u95ee\u3002\u907f\u514d\u60a8\u7684\u6570\u636e\u66b4\u9732\u5230\u516c\u7f51\u88ab\u522b\u4eba\u83b7\u53d6 \u8fdb\u5165ComfyUI\u4f7f\u7528\u754c\u9762 \u53c2\u6570\u8bf4\u660e \u53c2\u6570\u7ec4 \u53c2\u6570\u9879 \u8bf4\u660e \u670d\u52a1\u5b9e\u4f8b \u670d\u52a1\u5b9e\u4f8b\u540d\u79f0 \u957f\u5ea6\u4e0d\u8d85\u8fc764\u4e2a\u5b57\u7b26\uff0c\u5fc5\u987b\u4ee5\u82f1\u6587\u5b57\u6bcd\u5f00\u5934\uff0c\u53ef\u5305\u542b\u6570\u5b57\u3001\u82f1\u6587\u5b57\u6bcd\u3001\u77ed\u5212\u7ebf\uff08-\uff09\u548c\u4e0b\u5212\u7ebf\uff08_\uff09 \u5730\u57df \u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u7684\u5730\u57df \u4ed8\u8d39\u7c7b\u578b \u8d44\u6e90\u7684\u8ba1\u8d39\u7c7b\u578b\uff1a\u6309\u91cf\u4ed8\u8d39\u548c\u5305\u5e74\u5305\u6708 ECS\u5b9e\u4f8b\u914d\u7f6e \u5b9e\u4f8b\u7c7b\u578b \u53ef\u7528\u533a\u4e0b\u53ef\u4ee5\u4f7f\u7528\u7684\u5b9e\u4f8b\u89c4\u683c \u7f51\u7edc\u914d\u7f6e \u53ef\u7528\u533a ECS\u5b9e\u4f8b\u6240\u5728\u53ef\u7528\u533a VPC ID \u8d44\u6e90\u6240\u5728VPC \u4ea4\u6362\u673aID \u8d44\u6e90\u6240\u5728\u4ea4\u6362\u673a \u5185\u7f6e\u6a21\u578b\u8bf4\u660e \u4e3b\u8981\u6a21\u578b\u6982\u89c8 \u6a21\u578b\u540d\u79f0 \u7c7b\u578b \u53c2\u6570\u89c4\u6a21 \u5206\u8fa8\u7387 \u91cf\u5316\u683c\u5f0f \u7b80\u4ecb Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors \u56fe\u751f\u89c6\u9891 14B 480P FP8 E4M3FN WanVideo 2.1\u56fe\u751f\u89c6\u9891\u6a21\u578b\uff0c14B\u53c2\u6570\uff0c\u652f\u6301480P\u5206\u8fa8\u7387\u8f93\u51fa\uff0c\u4f7f\u7528FP8\u91cf\u5316\u4ee5\u8282\u7701\u663e\u5b58 Wan2_1-T2V-14B_fp8_e4m3fn.safetensors \u6587\u751f\u89c6\u9891 14B \u6807\u51c6 FP8 E4M3FN WanVideo 2.1\u6587\u751f\u89c6\u9891\u6a21\u578b\uff0c14B\u53c2\u6570\uff0c\u76f4\u63a5\u4ece\u6587\u672c\u751f\u6210\u89c6\u9891\uff0cFP8\u91cf\u5316\u7248\u672c flux1-dev.safetensors \u56fe\u50cf\u751f\u6210 - \u9ad8\u5206\u8fa8\u7387 \u6807\u51c6 Flux.1 Dev\u6a21\u578b\uff0c\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u652f\u6301\u9ad8\u5206\u8fa8\u7387\u8f93\u51fa\uff0c\u5f00\u53d1\u8005\u7248\u672c wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors \u6587\u751f\u89c6\u9891 1.3B \u6807\u51c6 FP8 E4M3FN WanVideo 2.1\u8f7b\u91cf\u7248\u6587\u751f\u89c6\u9891\u6a21\u578b\uff0c1.3B\u53c2\u6570\uff0c\u76f8\u6bd414B\u7248\u672c\u663e\u5b58\u9700\u6c42\u66f4\u4f4e\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883 vace-1.3b.safetensors \u89c6\u9891\u7f16\u8f91 1.3B \u6807\u51c6 \u6807\u51c6 VACE 1.3B\u89c6\u9891\u7f16\u8f91\u6a21\u578b\uff0c\u4e13\u6ce8\u4e8e\u89c6\u9891\u5185\u5bb9\u7f16\u8f91\u548c\u5904\u7406\uff0c\u8f7b\u91cf\u5316\u8bbe\u8ba1\uff0c\u9002\u5408\u5feb\u901f\u89c6\u9891\u7f16\u8f91\u4efb\u52a1 \u5b8c\u6574\u6a21\u578b\u8d44\u6e90\u6e05\u5355 \ud83d\udcca Model Categories Overview Category Directory Total Size Model Count Primary Function Diffusion Models /diffusion_models 53GB 6 models Core image/video generation Text Encoders /text_encoders 22GB 2 models Text understanding CLIP Models /clip 17GB 4 models Vision-language understanding Checkpoints /checkpoints 17GB 1 model Complete model checkpoints UNET Models /unet 14GB 1 model Neural network architecture VAE Models /vae 1.5GB 5 models Latent space processing CLIP Vision /clip_vision 2.4GB 1 model Visual understanding Face Restoration /facerestore_models 1.3GB 4 models Face enhancement Video Interpolation /interpolation 824MB 4 models Frame interpolation Content Safety /nsfw_detector 329MB 1 model Content moderation Upscaling /upscale_models 192MB 3 models Image super-resolution VAE Approximation /vae_approx 19MB 4 models Fast preview generation Text Embeddings /embeddings 260KB 2 models Negative prompts Configurations /configs 52KB 11 files Model configurations \ud83c\udfaf Diffusion Models ( /diffusion_models ) - 53GB Model Name Size Type Parameters Function Best For Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors 16GB Image\u2192Video 14B Animate static images Image animation Wan2_1-T2V-14B_fp8_e4m3fn.safetensors 14GB Text\u2192Video 14B Generate videos from text Text-to-video flux1-dev.safetensors 12GB Text\u2192Image - Experimental image generation Testing new features wan21_vace_1_3b.safetensors 6.7GB Video Editing 1.3B Enhanced video editing Professional editing wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors 1.4GB Text\u2192Video 1.3B Fast video generation Quick previews \ud83e\udde0 Text Encoders ( /text_encoders ) - 22GB Model Name Size Format Precision Function Best For wan2.1/umt5-xxl-enc-bf16.safetensors 11GB SafeTensors BF16 Multi-language text encoding High-quality generation wan2.1/models_t5_umt5-xxl-enc-bf16.pth 11GB PyTorch BF16 T5-based text encoding PyTorch workflows \ud83c\udfa8 CLIP Models ( /clip ) - 17GB Model Name Size Type Precision Function Best For t5xxl_fp16.safetensors 9.2GB T5 Text Encoder FP16 Advanced text understanding Complex prompts umt5_xxl_fp8_e4m3fn.safetensors 6.3GB UMT5 Encoder FP8 Efficient text encoding Resource optimization wan2.1/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors 1.2GB Multilingual CLIP FP16 Cross-language vision International content clip_l.safetensors 235MB CLIP Language - Vision-language alignment Standard workflows \ud83d\udcbe Checkpoints ( /checkpoints ) - 17GB Model Name Size Type Precision Function Best For flux1-schnell-fp8.safetensors 17GB Fast Image Gen FP8 Rapid image generation Production workflows \ud83d\udd27 UNET Models ( /unet ) - 14GB Model Name Size Type Quantization Function Best For Wan2.1_14B_VACE-Q6_K.gguf 14GB Video Editing Q6_K Professional video editing High-quality editing \ud83d\udd04 VAE Models ( /vae ) - 1.5GB Model Name Size Type Precision Function Best For ae.safetensors 320MB Standard VAE - Basic latent processing General use vae-ft-mse-840000-ema-pruned.safetensors 320MB Fine-tuned VAE - High-quality reconstruction Quality workflows diffusion_pytorch_model.safetensors 320MB Standard VAE - Broad compatibility General compatibility wan2.1/Wan2_1_VAE_bf16.safetensors 243MB Wan2.1 VAE BF16 Video-optimized processing Video generation wan21_vace_vae.safetensors 243MB VACE VAE - Video editing processing Video editing \ud83d\udc41\ufe0f CLIP Vision Models ( /clip_vision ) - 2.4GB Model Name Size Architecture Training Data Function Best For CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 2.4GB ViT-Huge-14 LAION-2B Visual understanding High-quality analysis \ud83c\udfac Video Interpolation Models ( /interpolation ) - 824MB GIMM-VFI Directory ( /interpolation/gimm-vfi & /interpolation/GIMM-VFI_safetensors ) Model Name Size Type Function Best For gimmvfi_f_arb_lpips_fp32.safetensors 117MB Full VFI Model Complete frame interpolation Production workflows gimmvfi_r_arb_lpips_fp32.safetensors 76MB Refinement Model Frame quality enhancement Quality improvement flowformer_sintel_fp32.safetensors 62MB Motion Model Advanced motion understanding Complex motion raft-things_fp32.safetensors 21MB Optical Flow Motion estimation Motion calculation \ud83d\udd0d Face Restoration Models ( /facerestore_models ) - 1.3GB Model Name Size Type Function Best For codeformer-v0.1.0.pth 360MB CodeFormer Advanced face enhancement Professional portraits GFPGANv1.4.pth 333MB GFPGAN v1.4 Improved face restoration High-quality restoration GFPGANv1.3.pth 333MB GFPGAN v1.3 Face restoration General face enhancement GPEN-BFR-512.onnx 272MB GPEN (ONNX) Real-time face restoration Fast processing \u2b06\ufe0f Upscaling Models ( /upscale_models ) - 192MB Model Name Size Scale Type Function Best For 8x_NMKD-Superscale_150000_G.pth 64MB 8x NMKD Extreme upscaling Maximum resolution 4x_foolhardy_Remacri.pth 64MB 4x Enhanced ESRGAN Sharp upscaling General upscaling 4x_NMKD-Siax_200k.pth 64MB 4x NMKD Siax Alternative upscaling Artistic enhancement \ud83d\udeab Content Safety Models ( /nsfw_detector ) - 329MB Model Name Size Architecture Function Best For vit-base-nsfw-detector/model.safetensors 329MB ViT-Base Content moderation Safety filtering Additional Files: - config.json - Model configuration - preprocessor_config.json - Input preprocessing - confusion_matrix.png - Performance metrics \u26a1 VAE Approximation Models ( /vae_approx ) - 19MB Model Name Size Target Function Best For taef1_decoder.pth 4.8MB SD3/FLUX Fast preview for SD3/FLUX Modern models taesd3_decoder.pth 4.8MB SD3 Fast preview for SD3 SD3 workflows taesdxl_decoder.pth 4.7MB SDXL Fast preview for SDXL SDXL workflows taesd_decoder.pth 4.7MB SD1.5 Fast preview for SD1.5 SD1.5 workflows \u5982\u4f55\u4e0a\u4f20\u81ea\u5df1\u7684\u6a21\u578b \u5728\u8ba1\u7b97\u5de2\u63a7\u5236\u53f0\u627e\u5230\u90e8\u7f72\u7684\u670d\u52a1\u5b9e\u4f8b\uff0c\u5e76\u5207\u6362Tab\u5230\u8d44\u6e90\u754c\u9762\uff0c\u5e76\u627e\u5230\u6240\u5c5e\u4ea7\u54c1\u4e3a\u5bf9\u8c61\u5b58\u50a8 OSS\u7684\u8d44\u6e90\uff0c\u70b9\u51fb\u8fdb\u5165\u3002 \u8bbf\u95ee\"\u6587\u4ef6\u5217\u8868\"\uff0c\u5728\u8def\u5f84\u4e3a/llm-model/model\u4e0b\u4e3a\u6240\u6709\u7c7b\u578b\u7684\u6a21\u578b\u3002 \u53ef\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u4e0a\u4f20\u6a21\u578b\uff0c\u5e76\u91cd\u542fcomfyui\u5ba2\u6237\u7aef\u5373\u53ef\u3002 \u6a21\u578b\u4e0b\u8f7d \u63a8\u8350\u524d\u5f80\u9b54\u642d\u4e0b\u8f7d \u6a21\u578b\u5b58\u50a8\u8def\u5f84\u4e3a\uff1a/root/storage/models \u4f7f\u7528\u6d41\u7a0b \u672c\u670d\u52a1\u5df2\u7ecf\u5185\u7f6e\u4e86\u4e24\u4e2a\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u7684\u5de5\u4f5c\u6d41\u3002\u5176\u4e2d\u6d89\u53ca\u7684\u63d2\u4ef6\u548c\u6a21\u578b\u4e5f\u5df2\u7ecf\u51c6\u5907\u597d\u3002 \u56fe\u751f\u89c6\u9891\u6216\u6587\u751f\u89c6\u9891\u529f\u80fd \u5728\u4e0b\u56fe\u5904\u9009\u62e9\u60f3\u8981\u7684\u529f\u80fd\u3002\u5efa\u8bae\u53ea\u9009\u62e9\u4e00\u79cd\u8fdb\u884c\u4f7f\u7528\uff0c\u907f\u514d\u7206\u5185\u5b58\u3002 \u6309\u56fe\u4e2d\u6307\u5f15\u9009\u62e9\u5de5\u4f5c\u6d41\u4fa7\u680f\uff0c\u9009\u62e9wanx-21.json\u5e76\u6253\u5f00\u3002 \u5728\u6b64\u5904\u9009\u62e9\u793a\u4f8b\u56fe\u7247\u6216\u9009\u62e9\u81ea\u5df1\u672c\u673a\u7535\u8111\u4e0a\u4f20\u3002 \u5728TextEncode\u5904\u586b\u5199\u63cf\u8ff0\u8bcd\u3002\u4e0a\u9762\u90e8\u5206\u662f\u4f60\u60f3\u8981\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4e0b\u9762\u90e8\u5206\u662f\u4f60\u4e0d\u60f3\u8981\u751f\u6210\u7684\u5185\u5bb9\u3002 \u5728ImageClip Encode\u5904\u53ef\u8bbe\u7f6e\u56fe\u7247\u7684\u5206\u8fa8\u7387\u548c\u5e27\u6570\u3002\u672c\u6a21\u578b\u6700\u9ad8\u53ef\u8bbe\u7f6e720*720\u3002 \u5176\u4f59\u53c2\u6570\u53ef\u53c2\u8003\u5b98\u7f51\uff1ahttps://comfyui-wiki.com/zh/interface/node-options \u6216\u4ee5\u4e0b\u6587\u6863\uff1ahttps://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/readme.md PS\uff1a\u5982\u679c\u4f7f\u7528vace\u6a21\u578b\uff0c\u53ef\u4f7f\u7528\u5de5\u4f5c\u6d41vace.json\u4f5c\u4e3a\u53c2\u8003 \u6587\u751f\u56fe\u529f\u80fd \u5de5\u4f5c\u6d41\u6846\u5904\u9009\u62e9\u8be5\u5de5\u4f5c\u6d41funny_pictures.json\u3002 \u8f93\u5165\u4f60\u60f3\u8981\u7684\u5185\u5bb9\u3002 \u8fd9\u91cc\u53ef\u4ee5\u8f93\u5165\u4e00\u4e9b\u6bd4\u8f83\u641e\u602a\u7684\u5185\u5bb9\uff0c\u6bd4\u5982\u6211\u8fd9\u91cc\u662f\u5173\u7fbd\u5927\u6218\u767d\u96ea\u516c\u4e3b\u3002 \u53ef\u4ee5\u5728\u6b64\u5904\u8bbe\u7f6e\u56fe\u7247\u7684\u5206\u8fa8\u7387\u548c\u56fe\u7247\u7684\u6570\u91cf\u3002\u5982\u679c\u60f3\u52a0\u5feb\u751f\u4ea7\u901f\u5ea6\uff0c\u53ef\u5c06batch_size\u8bbe\u7f6e\u4e3a1. \u7b49\u5f85\u56fe\u7247\u7684\u751f\u6210\u3002 \u56fe\u751f\u56fe\u529f\u80fd \u8bbf\u95ee\u6a21\u7248\uff0c\u6216\u81ea\u5df1\u5bfc\u5165\u5de5\u4f5c\u6d41\u4f7f\u7528\u3002 API\u8c03\u7528 API \u7aef\u70b9\u6982\u89c8 \u7aef\u70b9 \u65b9\u6cd5 \u529f\u80fd \u8bf4\u660e /queue GET \u83b7\u53d6\u961f\u5217\u72b6\u6001 \u67e5\u770b\u5f53\u524d\u4efb\u52a1\u961f\u5217 /prompt POST \u63d0\u4ea4\u5de5\u4f5c\u6d41 \u6267\u884c\u751f\u6210\u4efb\u52a1 /history/{prompt_id} GET \u83b7\u53d6\u6267\u884c\u5386\u53f2 \u67e5\u770b\u4efb\u52a1\u6267\u884c\u7ed3\u679c /upload/image POST \u4e0a\u4f20\u56fe\u7247 \u4e0a\u4f20\u8f93\u5165\u56fe\u7247\u6587\u4ef6 /view GET \u4e0b\u8f7d\u8f93\u51fa\u6587\u4ef6 \u83b7\u53d6\u751f\u6210\u7684\u7ed3\u679c\u6587\u4ef6 \u652f\u6301\u516c\u7f51\u6216\u8005\u79c1\u7f51\u7684API\u8c03\u7528\u3002 \u53ef\u53c2\u8003\u4e00\u4e0b\u4ee3\u7801\u5b9e\u73b0\u4e00\u4e2aAPI\u8c03\u7528\u7684\u811a\u672c\u3002 import requests import json import time def run_workflow_file(workflow_file, server=\"http://127.0.0.1:8188\"): \"\"\"\u8fd0\u884c\u672c\u5730\u5de5\u4f5c\u6d41JSON\u6587\u4ef6\"\"\" # \u52a0\u8f7d\u5de5\u4f5c\u6d41 with open(workflow_file, 'r', encoding='utf-8') as f: workflow = json.load(f) # \u63d0\u4ea4 response = requests.post(f\"{server}/prompt\", json={\"prompt\": workflow}) prompt_id = response.json()['prompt_id'] print(f\"\u4efb\u52a1\u63d0\u4ea4: {prompt_id}\") # \u7b49\u5f85\u5b8c\u6210 while True: response = requests.get(f\"{server}/history/{prompt_id}\") history = response.json() if prompt_id in history: break print(\"\u7b49\u5f85\u4e2d...\") time.sleep(3) # \u4e0b\u8f7d\u6240\u6709\u8f93\u51fa\u6587\u4ef6 outputs = history[prompt_id]['outputs'] for node_id, node_output in outputs.items(): # \u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u51fa for file_type in ['images', 'videos', 'gifs']: if file_type in node_output: for file_info in node_output[file_type]: filename = file_info['filename'] file_url = f\"{server}/view?filename={filename}&type=output\" response = requests.get(file_url) with open(filename, 'wb') as f: f.write(response.content) print(f\"\u5df2\u4e0b\u8f7d: {filename}\") # \u4f7f\u7528\u793a\u4f8b run_workflow_file(\"my_workflow.json\") \u5176\u4e2d\u672c\u5730\u5de5\u4f5c\u6d41\u91c7\u7528\u4e0b\u56fe\u63d0\u4f9b\u7684\u65b9\u5f0f\u6765\u83b7\u53d6\uff1a \u7531\u4e8eComfyui\u672a\u63d0\u4f9b\u5b98\u65b9\u7684API\u6587\u6863\uff0c\u6b64\u5904\u6839\u636e\u6587\u751f\u89c6\u9891\u548c\u56fe\u751f\u89c6\u9891\u63d0\u4f9b\u4e24\u4e2a\u5b8c\u6574\u7684\u793a\u4f8b\uff1a\u5173\u4e8e\u5982\u4f55\u4f7f\u7528API\u6765\u8c03\u7528\u5de5\u4f5c\u6d41\u8fdb\u884c\u6587\u751f\u56fe\u6216\u8005\u6587\u751f\u89c6\u9891\u7b49 \u8bbf\u95ee\uff1ahttps://github.com/aliyun-computenest/comfyui-acs/ \u627e\u5230demo\u6587\u4ef6\u5939 \u6587\u751f\u89c6\u9891API\u65b9\u5f0f \u6253\u5f00text_to_video_workflow.json\u4e3a\u5b9a\u4e49\u7684\u5de5\u4f5c\u6d41\uff0c\u786e\u8ba4\u597d\u6a21\u578b\u3002\uff08\u91cc\u9762\u9ed8\u8ba4\u5b9a\u4e49\u7684\u6a21\u578b\u4e3a14B\u7684\u4e07\u76f82.1\u6587\u751f\u89c6\u9891\u6a21\u578b\uff09 \u786e\u8ba4\u597dPrompt\u548c\u751f\u6210\u7684\u5206\u8fa8\u7387\u7b49\u53c2\u6570 \u4fee\u6539\u4ee3\u7801\u4e2dserver\u670d\u52a1\u5730\u5740\uff0c\u7531127.0.0.1\u5230\u4f60\u7684\u5b9e\u9645\u670d\u52a1\u5730\u5740\u3002 \u672c\u5730\u6267\u884cpython text_to_video_example.py\uff0c\u7b49\u5f85\u89c6\u9891\u751f\u6210 \u56fe\u751f\u89c6\u9891API\u65b9\u5f0f \u6253\u5f00image_to_video_workflow.json\u4e3a\u5b9a\u4e49\u7684\u5de5\u4f5c\u6d41\uff0c\u786e\u8ba4\u597d\u6a21\u578b\u3002\uff08\u91cc\u9762\u9ed8\u8ba4\u5b9a\u4e49\u7684\u6a21\u578b\u4e3a14B\u7684\u4e07\u76f82.1\u56fe\u751f\u89c6\u9891\u6a21\u578b\uff09 \u786e\u8ba4\u597dPrompt\u548c\u751f\u6210\u7684\u5206\u8fa8\u7387\u7b49\u53c2\u6570 \u4fee\u6539\u4ee3\u7801\u4e2dserver\u670d\u52a1\u5730\u5740\uff0c\u7531127.0.0.1\u5230\u4f60\u7684\u5b9e\u9645\u670d\u52a1\u5730\u5740\u3002 \u672c\u5730\u6267\u884cpython image_to_video_example.py\uff0c\u7b49\u5f85\u89c6\u9891\u751f\u6210 \u8d26\u53f7\u5bc6\u7801 \u9ed8\u8ba4\u8d26\u53f7\u548c\u5bc6\u7801\u4e3a: 1. \u8d26\u53f7\uff1aadmin 2. \u5bc6\u7801\uff1aadmin \u5e38\u89c1\u95ee\u9898 \u51fa\u73b0\u67d0\u4e2a\u8282\u70b9\u7c7b\u578b\u4e0d\u5b58\u5728\uff0c\u901a\u8fc7manager\u5b89\u88c5\u7f3a\u5c11\u7684\u8282\u70b9\uff0c\u5e76\u91cd\u542f\u3002","title":"ComfyUI\u793e\u533a\u7248"},{"location":"#comfyui","text":"\u514d\u8d23\u58f0\u660e\uff1a \u672c\u670d\u52a1\u7531\u7b2c\u4e09\u65b9\u63d0\u4f9b\uff0c\u6211\u4eec\u5c3d\u529b\u786e\u4fdd\u5176\u5b89\u5168\u6027\u3001\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u5176\u5b8c\u5168\u514d\u4e8e\u6545\u969c\u3001\u4e2d\u65ad\u3001\u9519\u8bef\u6216\u653b\u51fb\u3002\u56e0\u6b64\uff0c\u672c\u516c\u53f8\u5728\u6b64\u58f0\u660e\uff1a\u5bf9\u4e8e\u672c\u670d\u52a1\u7684\u5185\u5bb9\u3001\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u53ef\u9760\u6027\u3001\u9002\u7528\u6027\u4ee5\u53ca\u53ca\u65f6\u6027\u4e0d\u4f5c\u4efb\u4f55\u9648\u8ff0\u3001\u4fdd\u8bc1\u6216\u627f\u8bfa\uff0c\u4e0d\u5bf9\u60a8\u4f7f\u7528\u672c\u670d\u52a1\u6240\u4ea7\u751f\u7684\u4efb\u4f55\u76f4\u63a5\u6216\u95f4\u63a5\u7684\u635f\u5931\u6216\u635f\u5bb3\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff1b\u5bf9\u4e8e\u60a8\u901a\u8fc7\u672c\u670d\u52a1\u8bbf\u95ee\u7684\u7b2c\u4e09\u65b9\u7f51\u7ad9\u3001\u5e94\u7528\u7a0b\u5e8f\u3001\u4ea7\u54c1\u548c\u670d\u52a1\uff0c\u4e0d\u5bf9\u5176\u5185\u5bb9\u3001\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u53ef\u9760\u6027\u3001\u9002\u7528\u6027\u4ee5\u53ca\u53ca\u65f6\u6027\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u60a8\u5e94\u81ea\u884c\u627f\u62c5\u4f7f\u7528\u540e\u679c\u4ea7\u751f\u7684\u98ce\u9669\u548c\u8d23\u4efb\uff1b\u5bf9\u4e8e\u56e0\u60a8\u4f7f\u7528\u672c\u670d\u52a1\u800c\u4ea7\u751f\u7684\u4efb\u4f55\u635f\u5931\u3001\u635f\u5bb3\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u76f4\u63a5\u635f\u5931\u3001\u95f4\u63a5\u635f\u5931\u3001\u5229\u6da6\u635f\u5931\u3001\u5546\u8a89\u635f\u5931\u3001\u6570\u636e\u635f\u5931\u6216\u5176\u4ed6\u7ecf\u6d4e\u635f\u5931\uff0c\u4e0d\u627f\u62c5\u4efb\u4f55\u8d23\u4efb\uff0c\u5373\u4f7f\u672c\u516c\u53f8\u4e8b\u5148\u5df2\u88ab\u544a\u77e5\u53ef\u80fd\u5b58\u5728\u6b64\u7c7b\u635f\u5931\u6216\u635f\u5bb3\u7684\u53ef\u80fd\u6027\uff1b\u6211\u4eec\u4fdd\u7559\u4e0d\u65f6\u4fee\u6539\u672c\u58f0\u660e\u7684\u6743\u5229\uff0c\u56e0\u6b64\u8bf7\u60a8\u5728\u4f7f\u7528\u672c\u670d\u52a1\u524d\u5b9a\u671f\u68c0\u67e5\u672c\u58f0\u660e\u3002\u5982\u679c\u60a8\u5bf9\u672c\u58f0\u660e\u6216\u672c\u670d\u52a1\u5b58\u5728\u4efb\u4f55\u95ee\u9898\u6216\u7591\u95ee\uff0c\u8bf7\u8054\u7cfb\u6211\u4eec\u3002","title":"ComfyUI\u793e\u533a\u7248"},{"location":"#_1","text":"ComfyUI\u662f \u6700\u5f3a\u5927\u7684\u5f00\u6e90\u8282\u70b9\u5f0f\u751f\u6210\u5f0fAI\u5e94\u7528\uff0c\u652f\u6301\u521b\u5efa\u56fe\u50cf\u3001\u89c6\u9891\u53ca\u97f3\u9891\u5185\u5bb9\u3002\u4f9d\u6258\u524d\u6cbf\u5f00\u6e90\u6a21\u578b\u53ef\u5b9e\u73b0\u89c6\u9891\u4e0e\u56fe\u50cf\u751f\u6210\u3002 \u4f9d\u636e\u5b98\u65b9\u6587\u6863\uff0cComfyUI\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a + \u8282\u70b9/\u56fe\u5f62/\u6d41\u7a0b\u56fe\u754c\u9762\uff0c\u7528\u4e8e\u5b9e\u9a8c\u548c\u521b\u5efa\u590d\u6742\u7684\u7a33\u5b9a\u6269\u6563\u5de5\u4f5c\u6d41\u7a0b\uff0c\u65e0\u9700\u7f16\u5199\u4efb\u4f55\u4ee3\u7801\u3002 + \u5b8c\u5168\u652f\u6301 SD1.x\u3001SD2.x \u548c SDXL + \u5f02\u6b65\u961f\u5217\u7cfb\u7edf + \u591a\u9879\u4f18\u5316 \u53ea\u91cd\u65b0\u6267\u884c\u5de5\u4f5c\u6d41\u4e2d\u5728\u4e24\u6b21\u6267\u884c\u4e4b\u95f4\u53d1\u751f\u53d8\u5316\u7684\u90e8\u5206\u3002 + \u547d\u4ee4\u884c\u9009\u9879\uff1a--lowvram \u53ef\u4f7f\u5176\u5728 3GB \u5185\u5b58\u4ee5\u4e0b\u7684 GPU \u4e0a\u8fd0\u884c\uff08\u5728\u4f4e\u5185\u5b58\u7684 GPU \u4e0a\u81ea\u52a8\u542f\u7528\uff09 + \u5373\u4f7f\u6ca1\u6709 GPU \u4e5f\u80fd\u4f7f\u7528\uff1a --cpu\uff08\u6162\u901f\uff09 + \u53ef\u52a0\u8f7d ckpt\u3001safetensors \u548c diffusers \u6a21\u578b/\u68c0\u67e5\u70b9\u3002\u72ec\u7acb\u7684 VAE \u548c CLIP \u6a21\u578b\u3002 + \u5d4c\u5165/\u6587\u672c\u53cd\u6f14 + Loras \uff08\u5e38\u89c4\u3001locon \u548c loha\uff09 + \u8d85\u7f51\u7edc + \u4ece\u751f\u6210\u7684 PNG \u6587\u4ef6\u52a0\u8f7d\u5b8c\u6574\u7684\u5de5\u4f5c\u6d41\uff08\u542b\u79cd\u5b50 + \u4ee5 Json \u6587\u4ef6\u4fdd\u5b58/\u52a0\u8f7d\u5de5\u4f5c\u6d41\u3002 + \u8282\u70b9\u754c\u9762\u53ef\u7528\u4e8e\u521b\u5efa\u590d\u6742\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5982 \"Hires fix \"\u6216\u66f4\u9ad8\u7ea7\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002 + \u533a\u57df\u5408\u6210 + \u4f7f\u7528\u5e38\u89c4\u548c\u5185\u7ed8\u6a21\u578b\u8fdb\u884c\u5185\u7ed8\u3002 + \u63a7\u5236\u7f51\u7edc\u548c T2I \u9002\u914d\u5668 + \u5347\u7ea7\u6a21\u578b\uff08ESRGAN\u3001ESRGAN \u53d8\u4f53\u3001SwinIR\u3001Swin2SR \u7b49\uff09 + unCLIP \u6a21\u578b + GLIGEN + \u6a21\u578b\u5408\u5e76 + \u4f7f\u7528 TAESD \u8fdb\u884c\u6f5c\u4f0f\u9884\u89c8 + \u542f\u52a8\u901f\u5ea6\u6781\u5feb\u3002 + \u5b8c\u5168\u79bb\u7ebf\u5de5\u4f5c\uff1a\u4e0d\u4f1a\u4e0b\u8f7d\u4efb\u4f55\u4e1c\u897f\u3002 + \u914d\u7f6e\u6587\u4ef6\u53ef\u8bbe\u7f6e\u6a21\u578b\u7684\u641c\u7d22\u8def\u5f84\u3002","title":"\u6982\u8ff0"},{"location":"#_2","text":"\u90e8\u7f72ComfyUI\u793e\u533a\u7248\u670d\u52a1\u5b9e\u4f8b\uff0c\u9700\u8981\u5bf9\u90e8\u5206\u963f\u91cc\u4e91\u8d44\u6e90\u8fdb\u884c\u8bbf\u95ee\u548c\u521b\u5efa\u64cd\u4f5c\u3002\u56e0\u6b64\u60a8\u7684\u8d26\u53f7\u9700\u8981\u5305\u542b\u5982\u4e0b\u8d44\u6e90\u7684\u6743\u9650\u3002 \u8bf4\u660e \uff1a\u5f53\u60a8\u7684\u8d26\u53f7\u662fRAM\u8d26\u53f7\u65f6\uff0c\u624d\u9700\u8981\u6dfb\u52a0\u6b64\u6743\u9650\u3002 \u6743\u9650\u7b56\u7565\u540d\u79f0 \u5907\u6ce8 AliyunECSFullAccess \u7ba1\u7406\u4e91\u670d\u52a1\u5668\u670d\u52a1\uff08ECS\uff09\u7684\u6743\u9650 AliyunVPCFullAccess \u7ba1\u7406\u4e13\u6709\u7f51\u7edc\uff08VPC\uff09\u7684\u6743\u9650 AliyunROSFullAccess \u7ba1\u7406\u8d44\u6e90\u7f16\u6392\u670d\u52a1\uff08ROS\uff09\u7684\u6743\u9650 AliyunCSFullAccess \u7ba1\u7406\u5bb9\u5668\u670d\u52a1\uff08CS\uff09\u7684\u6743\u9650 AliyunComputeNestUserFullAccess \u7ba1\u7406\u8ba1\u7b97\u5de2\u670d\u52a1\uff08ComputeNest\uff09\u7684\u7528\u6237\u4fa7\u6743\u9650 AliyunOSSFullAccess \u7ba1\u7406\u7f51\u7edc\u5bf9\u8c61\u5b58\u50a8\u670d\u52a1\uff08OSS\uff09\u7684\u6743\u9650","title":"\u524d\u63d0\u6761\u4ef6"},{"location":"#_3","text":"","title":"\u8ba1\u8d39\u8bf4\u660e"},{"location":"#acs","text":"\u672c\u670d\u52a1\u5728\u963f\u91cc\u4e91\u4e0a\u7684\u8d39\u7528\u4e3b\u8981\u6d89\u53ca\uff1a * ACS\u8d39\u7528 * \u8df3\u677f\u673aECS\u8d39\u7528 * \u8bf4\u660e\uff1a\u8be5ECS\u7528\u4e8e\u90e8\u7f72\u548c\u7ba1\u7406K8S\u96c6\u7fa4\uff0c/root\u76ee\u5f55\u4e2d\u4fdd\u5b58\u4e86\u90e8\u7f72\u6240\u7528\u5230\u7684K8S Yaml\u8d44\u6e90\u6587\u4ef6\uff0c\u540e\u671f\u9700\u8981\u4fee\u6539\u4e86\u53c2\u6570\u91cd\u65b0\u90e8\u7f72\u53ef\u4ee5\u76f4\u63a5\u5728\u8be5\u57fa\u7840\u4e0a\u4fee\u6539\u540e\u91cd\u65b0\u6267\u884ckubectl apply\u3002 \u90e8\u7f72\u5b8c\u6210\u5982\u4e0d\u9700\u8981\u4e5f\u53ef\u81ea\u884c\u91ca\u653e\u3002 * OSS\u8d39\u7528 \u8ba1\u8d39\u65b9\u5f0f\uff1a\u6309\u91cf\u4ed8\u8d39\uff08\u5c0f\u65f6\uff09\u6216\u5305\u5e74\u5305\u6708 \u9884\u4f30\u8d39\u7528\u5728\u521b\u5efa\u5b9e\u4f8b\u65f6\u53ef\u5b9e\u65f6\u770b\u5230\u3002","title":"ACS\u7248\u672c\u8d39\u7528"},{"location":"#_4","text":"\u793e\u533a\u7248\u5728\u8ba1\u7b97\u5de2\u90e8\u7f72\u7684\u8d39\u7528\u4e3b\u8981\u6d89\u53ca\uff1a + \u6240\u9009vCPU\u4e0e\u5185\u5b58\u89c4\u683c + \u7cfb\u7edf\u76d8\u7c7b\u578b\u53ca\u5bb9\u91cf + \u516c\u7f51\u5e26\u5bbd","title":"\u793e\u533a\u7248\u8d39\u7528"},{"location":"#_5","text":"","title":"\u6574\u4f53\u67b6\u6784"},{"location":"#_6","text":"","title":"\u90e8\u7f72\u6d41\u7a0b"},{"location":"#acs_1","text":"\u5355\u51fb \u90e8\u7f72\u94fe\u63a5 \u3002\u6839\u636e\u754c\u9762\u63d0\u793a\u586b\u5199\u53c2\u6570\uff0c\u53ef\u4ee5\u770b\u5230\u5bf9\u5e94\u8be2\u4ef7\u660e\u7ec6\uff0c\u786e\u8ba4\u53c2\u6570\u540e\u70b9\u51fb \u4e0b\u4e00\u6b65\uff1a\u786e\u8ba4\u8ba2\u5355 \u3002 \u70b9\u51fb \u4e0b\u4e00\u6b65\uff1a\u786e\u8ba4\u8ba2\u5355 \u540e\u53ef\u4ee5\u4e5f\u770b\u5230\u4ef7\u683c\u9884\u89c8\uff0c\u968f\u540e\u70b9\u51fb \u7acb\u5373\u90e8\u7f72 \uff0c\u7b49\u5f85\u90e8\u7f72\u5b8c\u6210\u3002 \u7b49\u5f85\u90e8\u7f72\u5b8c\u6210\u540e\u5c31\u53ef\u4ee5\u5f00\u59cb\u4f7f\u7528\u670d\u52a1\u3002","title":"ACS\u7248\u672c\u90e8\u7f72"},{"location":"#ecs","text":"\u8bbf\u95ee\u8ba1\u7b97\u5de2 \u90e8\u7f72\u94fe\u63a5 \uff0c\u6309\u63d0\u793a\u586b\u5199\u90e8\u7f72\u53c2\u6570 \u586b\u5199\u5b9e\u4f8b\u53c2\u6570 \uff0c\u9009\u62e9\u4f60\u60f3\u8d2d\u4e70\u7684\u65b9\u5f0f\u548c\u5b9e\u4f8b\u7c7b\u578b\u3002 \u6ce8\u610f \u5982\u679c\u60a8\u60f3\u8981\u4f7f\u7528\u56fe\u751f\u89c6\u9891\u529f\u80fd\uff0c\u4e3a\u4e86\u964d\u4f4e\u7206RAM\u5185\u5b58\u7684\u53ef\u80fd\uff0c\u8bf7\u9009\u62e960G\u4ee5\u4e0a\u7684\u5185\u5b58\u89c4\u683c+A10\u4ee5\u4e0a\u7684\u663e\u5361\u89c4\u683c\u3002 \u6839\u636e\u9700\u6c42\u9009\u62e9\u65b0\u5efa\u4e13\u7528\u7f51\u7edc\u6216\u76f4\u63a5\u4f7f\u7528\u5df2\u6709\u7684\u4e13\u6709\u7f51\u7edc\u3002\u586b\u5199\u53ef\u7528\u533a\u548c\u7f51\u7edc\u53c2\u6570 \u70b9\u51fb\u7acb\u5373\u521b\u5efa\uff0c\u7b49\u5f85\u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u5b8c\u6210 \u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u5b8c\u6210\u540e\uff0c\u70b9\u51fb\u5b9e\u4f8bID\u8fdb\u5165\u5230\u8be6\u60c5\u754c\u9762 \u8bbf\u95ee\u670d\u52a1\u5b9e\u4f8b\u7684\u4f7f\u7528URL\uff0c\u8fd9\u91cc\u6211\u4eec\u91c7\u7528\u5b89\u5168\u4ee3\u7406\u76f4\u63a5\u8bbf\u95ee\u3002\u907f\u514d\u60a8\u7684\u6570\u636e\u66b4\u9732\u5230\u516c\u7f51\u88ab\u522b\u4eba\u83b7\u53d6 \u8fdb\u5165ComfyUI\u4f7f\u7528\u754c\u9762","title":"ECS\u793e\u533a\u7248\u90e8\u7f72"},{"location":"#_7","text":"\u53c2\u6570\u7ec4 \u53c2\u6570\u9879 \u8bf4\u660e \u670d\u52a1\u5b9e\u4f8b \u670d\u52a1\u5b9e\u4f8b\u540d\u79f0 \u957f\u5ea6\u4e0d\u8d85\u8fc764\u4e2a\u5b57\u7b26\uff0c\u5fc5\u987b\u4ee5\u82f1\u6587\u5b57\u6bcd\u5f00\u5934\uff0c\u53ef\u5305\u542b\u6570\u5b57\u3001\u82f1\u6587\u5b57\u6bcd\u3001\u77ed\u5212\u7ebf\uff08-\uff09\u548c\u4e0b\u5212\u7ebf\uff08_\uff09 \u5730\u57df \u670d\u52a1\u5b9e\u4f8b\u90e8\u7f72\u7684\u5730\u57df \u4ed8\u8d39\u7c7b\u578b \u8d44\u6e90\u7684\u8ba1\u8d39\u7c7b\u578b\uff1a\u6309\u91cf\u4ed8\u8d39\u548c\u5305\u5e74\u5305\u6708 ECS\u5b9e\u4f8b\u914d\u7f6e \u5b9e\u4f8b\u7c7b\u578b \u53ef\u7528\u533a\u4e0b\u53ef\u4ee5\u4f7f\u7528\u7684\u5b9e\u4f8b\u89c4\u683c \u7f51\u7edc\u914d\u7f6e \u53ef\u7528\u533a ECS\u5b9e\u4f8b\u6240\u5728\u53ef\u7528\u533a VPC ID \u8d44\u6e90\u6240\u5728VPC \u4ea4\u6362\u673aID \u8d44\u6e90\u6240\u5728\u4ea4\u6362\u673a","title":"\u53c2\u6570\u8bf4\u660e"},{"location":"#_8","text":"","title":"\u5185\u7f6e\u6a21\u578b\u8bf4\u660e"},{"location":"#_9","text":"\u6a21\u578b\u540d\u79f0 \u7c7b\u578b \u53c2\u6570\u89c4\u6a21 \u5206\u8fa8\u7387 \u91cf\u5316\u683c\u5f0f \u7b80\u4ecb Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors \u56fe\u751f\u89c6\u9891 14B 480P FP8 E4M3FN WanVideo 2.1\u56fe\u751f\u89c6\u9891\u6a21\u578b\uff0c14B\u53c2\u6570\uff0c\u652f\u6301480P\u5206\u8fa8\u7387\u8f93\u51fa\uff0c\u4f7f\u7528FP8\u91cf\u5316\u4ee5\u8282\u7701\u663e\u5b58 Wan2_1-T2V-14B_fp8_e4m3fn.safetensors \u6587\u751f\u89c6\u9891 14B \u6807\u51c6 FP8 E4M3FN WanVideo 2.1\u6587\u751f\u89c6\u9891\u6a21\u578b\uff0c14B\u53c2\u6570\uff0c\u76f4\u63a5\u4ece\u6587\u672c\u751f\u6210\u89c6\u9891\uff0cFP8\u91cf\u5316\u7248\u672c flux1-dev.safetensors \u56fe\u50cf\u751f\u6210 - \u9ad8\u5206\u8fa8\u7387 \u6807\u51c6 Flux.1 Dev\u6a21\u578b\uff0c\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u652f\u6301\u9ad8\u5206\u8fa8\u7387\u8f93\u51fa\uff0c\u5f00\u53d1\u8005\u7248\u672c wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors \u6587\u751f\u89c6\u9891 1.3B \u6807\u51c6 FP8 E4M3FN WanVideo 2.1\u8f7b\u91cf\u7248\u6587\u751f\u89c6\u9891\u6a21\u578b\uff0c1.3B\u53c2\u6570\uff0c\u76f8\u6bd414B\u7248\u672c\u663e\u5b58\u9700\u6c42\u66f4\u4f4e\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883 vace-1.3b.safetensors \u89c6\u9891\u7f16\u8f91 1.3B \u6807\u51c6 \u6807\u51c6 VACE 1.3B\u89c6\u9891\u7f16\u8f91\u6a21\u578b\uff0c\u4e13\u6ce8\u4e8e\u89c6\u9891\u5185\u5bb9\u7f16\u8f91\u548c\u5904\u7406\uff0c\u8f7b\u91cf\u5316\u8bbe\u8ba1\uff0c\u9002\u5408\u5feb\u901f\u89c6\u9891\u7f16\u8f91\u4efb\u52a1","title":"\u4e3b\u8981\u6a21\u578b\u6982\u89c8"},{"location":"#_10","text":"","title":"\u5b8c\u6574\u6a21\u578b\u8d44\u6e90\u6e05\u5355"},{"location":"#model-categories-overview","text":"Category Directory Total Size Model Count Primary Function Diffusion Models /diffusion_models 53GB 6 models Core image/video generation Text Encoders /text_encoders 22GB 2 models Text understanding CLIP Models /clip 17GB 4 models Vision-language understanding Checkpoints /checkpoints 17GB 1 model Complete model checkpoints UNET Models /unet 14GB 1 model Neural network architecture VAE Models /vae 1.5GB 5 models Latent space processing CLIP Vision /clip_vision 2.4GB 1 model Visual understanding Face Restoration /facerestore_models 1.3GB 4 models Face enhancement Video Interpolation /interpolation 824MB 4 models Frame interpolation Content Safety /nsfw_detector 329MB 1 model Content moderation Upscaling /upscale_models 192MB 3 models Image super-resolution VAE Approximation /vae_approx 19MB 4 models Fast preview generation Text Embeddings /embeddings 260KB 2 models Negative prompts Configurations /configs 52KB 11 files Model configurations","title":"\ud83d\udcca Model Categories Overview"},{"location":"#diffusion-models-diffusion_models-53gb","text":"Model Name Size Type Parameters Function Best For Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors 16GB Image\u2192Video 14B Animate static images Image animation Wan2_1-T2V-14B_fp8_e4m3fn.safetensors 14GB Text\u2192Video 14B Generate videos from text Text-to-video flux1-dev.safetensors 12GB Text\u2192Image - Experimental image generation Testing new features wan21_vace_1_3b.safetensors 6.7GB Video Editing 1.3B Enhanced video editing Professional editing wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors 1.4GB Text\u2192Video 1.3B Fast video generation Quick previews","title":"\ud83c\udfaf Diffusion Models (/diffusion_models) - 53GB"},{"location":"#text-encoders-text_encoders-22gb","text":"Model Name Size Format Precision Function Best For wan2.1/umt5-xxl-enc-bf16.safetensors 11GB SafeTensors BF16 Multi-language text encoding High-quality generation wan2.1/models_t5_umt5-xxl-enc-bf16.pth 11GB PyTorch BF16 T5-based text encoding PyTorch workflows","title":"\ud83e\udde0 Text Encoders (/text_encoders) - 22GB"},{"location":"#clip-models-clip-17gb","text":"Model Name Size Type Precision Function Best For t5xxl_fp16.safetensors 9.2GB T5 Text Encoder FP16 Advanced text understanding Complex prompts umt5_xxl_fp8_e4m3fn.safetensors 6.3GB UMT5 Encoder FP8 Efficient text encoding Resource optimization wan2.1/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors 1.2GB Multilingual CLIP FP16 Cross-language vision International content clip_l.safetensors 235MB CLIP Language - Vision-language alignment Standard workflows","title":"\ud83c\udfa8 CLIP Models (/clip) - 17GB"},{"location":"#checkpoints-checkpoints-17gb","text":"Model Name Size Type Precision Function Best For flux1-schnell-fp8.safetensors 17GB Fast Image Gen FP8 Rapid image generation Production workflows","title":"\ud83d\udcbe Checkpoints (/checkpoints) - 17GB"},{"location":"#unet-models-unet-14gb","text":"Model Name Size Type Quantization Function Best For Wan2.1_14B_VACE-Q6_K.gguf 14GB Video Editing Q6_K Professional video editing High-quality editing","title":"\ud83d\udd27 UNET Models (/unet) - 14GB"},{"location":"#vae-models-vae-15gb","text":"Model Name Size Type Precision Function Best For ae.safetensors 320MB Standard VAE - Basic latent processing General use vae-ft-mse-840000-ema-pruned.safetensors 320MB Fine-tuned VAE - High-quality reconstruction Quality workflows diffusion_pytorch_model.safetensors 320MB Standard VAE - Broad compatibility General compatibility wan2.1/Wan2_1_VAE_bf16.safetensors 243MB Wan2.1 VAE BF16 Video-optimized processing Video generation wan21_vace_vae.safetensors 243MB VACE VAE - Video editing processing Video editing","title":"\ud83d\udd04 VAE Models (/vae) - 1.5GB"},{"location":"#clip-vision-models-clip_vision-24gb","text":"Model Name Size Architecture Training Data Function Best For CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 2.4GB ViT-Huge-14 LAION-2B Visual understanding High-quality analysis","title":"\ud83d\udc41\ufe0f CLIP Vision Models (/clip_vision) - 2.4GB"},{"location":"#video-interpolation-models-interpolation-824mb","text":"","title":"\ud83c\udfac Video Interpolation Models (/interpolation) - 824MB"},{"location":"#gimm-vfi-directory-interpolationgimm-vfi-interpolationgimm-vfi_safetensors","text":"Model Name Size Type Function Best For gimmvfi_f_arb_lpips_fp32.safetensors 117MB Full VFI Model Complete frame interpolation Production workflows gimmvfi_r_arb_lpips_fp32.safetensors 76MB Refinement Model Frame quality enhancement Quality improvement flowformer_sintel_fp32.safetensors 62MB Motion Model Advanced motion understanding Complex motion raft-things_fp32.safetensors 21MB Optical Flow Motion estimation Motion calculation","title":"GIMM-VFI Directory (/interpolation/gimm-vfi &amp; /interpolation/GIMM-VFI_safetensors)"},{"location":"#face-restoration-models-facerestore_models-13gb","text":"Model Name Size Type Function Best For codeformer-v0.1.0.pth 360MB CodeFormer Advanced face enhancement Professional portraits GFPGANv1.4.pth 333MB GFPGAN v1.4 Improved face restoration High-quality restoration GFPGANv1.3.pth 333MB GFPGAN v1.3 Face restoration General face enhancement GPEN-BFR-512.onnx 272MB GPEN (ONNX) Real-time face restoration Fast processing","title":"\ud83d\udd0d Face Restoration Models (/facerestore_models) - 1.3GB"},{"location":"#upscaling-models-upscale_models-192mb","text":"Model Name Size Scale Type Function Best For 8x_NMKD-Superscale_150000_G.pth 64MB 8x NMKD Extreme upscaling Maximum resolution 4x_foolhardy_Remacri.pth 64MB 4x Enhanced ESRGAN Sharp upscaling General upscaling 4x_NMKD-Siax_200k.pth 64MB 4x NMKD Siax Alternative upscaling Artistic enhancement","title":"\u2b06\ufe0f Upscaling Models (/upscale_models) - 192MB"},{"location":"#content-safety-models-nsfw_detector-329mb","text":"Model Name Size Architecture Function Best For vit-base-nsfw-detector/model.safetensors 329MB ViT-Base Content moderation Safety filtering Additional Files: - config.json - Model configuration - preprocessor_config.json - Input preprocessing - confusion_matrix.png - Performance metrics","title":"\ud83d\udeab Content Safety Models (/nsfw_detector) - 329MB"},{"location":"#vae-approximation-models-vae_approx-19mb","text":"Model Name Size Target Function Best For taef1_decoder.pth 4.8MB SD3/FLUX Fast preview for SD3/FLUX Modern models taesd3_decoder.pth 4.8MB SD3 Fast preview for SD3 SD3 workflows taesdxl_decoder.pth 4.7MB SDXL Fast preview for SDXL SDXL workflows taesd_decoder.pth 4.7MB SD1.5 Fast preview for SD1.5 SD1.5 workflows","title":"\u26a1 VAE Approximation Models (/vae_approx) - 19MB"},{"location":"#_11","text":"\u5728\u8ba1\u7b97\u5de2\u63a7\u5236\u53f0\u627e\u5230\u90e8\u7f72\u7684\u670d\u52a1\u5b9e\u4f8b\uff0c\u5e76\u5207\u6362Tab\u5230\u8d44\u6e90\u754c\u9762\uff0c\u5e76\u627e\u5230\u6240\u5c5e\u4ea7\u54c1\u4e3a\u5bf9\u8c61\u5b58\u50a8 OSS\u7684\u8d44\u6e90\uff0c\u70b9\u51fb\u8fdb\u5165\u3002 \u8bbf\u95ee\"\u6587\u4ef6\u5217\u8868\"\uff0c\u5728\u8def\u5f84\u4e3a/llm-model/model\u4e0b\u4e3a\u6240\u6709\u7c7b\u578b\u7684\u6a21\u578b\u3002 \u53ef\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u4e0a\u4f20\u6a21\u578b\uff0c\u5e76\u91cd\u542fcomfyui\u5ba2\u6237\u7aef\u5373\u53ef\u3002","title":"\u5982\u4f55\u4e0a\u4f20\u81ea\u5df1\u7684\u6a21\u578b"},{"location":"#_12","text":"\u63a8\u8350\u524d\u5f80\u9b54\u642d\u4e0b\u8f7d \u6a21\u578b\u5b58\u50a8\u8def\u5f84\u4e3a\uff1a/root/storage/models","title":"\u6a21\u578b\u4e0b\u8f7d"},{"location":"#_13","text":"\u672c\u670d\u52a1\u5df2\u7ecf\u5185\u7f6e\u4e86\u4e24\u4e2a\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u7684\u5de5\u4f5c\u6d41\u3002\u5176\u4e2d\u6d89\u53ca\u7684\u63d2\u4ef6\u548c\u6a21\u578b\u4e5f\u5df2\u7ecf\u51c6\u5907\u597d\u3002","title":"\u4f7f\u7528\u6d41\u7a0b"},{"location":"#_14","text":"\u5728\u4e0b\u56fe\u5904\u9009\u62e9\u60f3\u8981\u7684\u529f\u80fd\u3002\u5efa\u8bae\u53ea\u9009\u62e9\u4e00\u79cd\u8fdb\u884c\u4f7f\u7528\uff0c\u907f\u514d\u7206\u5185\u5b58\u3002 \u6309\u56fe\u4e2d\u6307\u5f15\u9009\u62e9\u5de5\u4f5c\u6d41\u4fa7\u680f\uff0c\u9009\u62e9wanx-21.json\u5e76\u6253\u5f00\u3002 \u5728\u6b64\u5904\u9009\u62e9\u793a\u4f8b\u56fe\u7247\u6216\u9009\u62e9\u81ea\u5df1\u672c\u673a\u7535\u8111\u4e0a\u4f20\u3002 \u5728TextEncode\u5904\u586b\u5199\u63cf\u8ff0\u8bcd\u3002\u4e0a\u9762\u90e8\u5206\u662f\u4f60\u60f3\u8981\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4e0b\u9762\u90e8\u5206\u662f\u4f60\u4e0d\u60f3\u8981\u751f\u6210\u7684\u5185\u5bb9\u3002 \u5728ImageClip Encode\u5904\u53ef\u8bbe\u7f6e\u56fe\u7247\u7684\u5206\u8fa8\u7387\u548c\u5e27\u6570\u3002\u672c\u6a21\u578b\u6700\u9ad8\u53ef\u8bbe\u7f6e720*720\u3002 \u5176\u4f59\u53c2\u6570\u53ef\u53c2\u8003\u5b98\u7f51\uff1ahttps://comfyui-wiki.com/zh/interface/node-options \u6216\u4ee5\u4e0b\u6587\u6863\uff1ahttps://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/readme.md PS\uff1a\u5982\u679c\u4f7f\u7528vace\u6a21\u578b\uff0c\u53ef\u4f7f\u7528\u5de5\u4f5c\u6d41vace.json\u4f5c\u4e3a\u53c2\u8003","title":"\u56fe\u751f\u89c6\u9891\u6216\u6587\u751f\u89c6\u9891\u529f\u80fd"},{"location":"#_15","text":"\u5de5\u4f5c\u6d41\u6846\u5904\u9009\u62e9\u8be5\u5de5\u4f5c\u6d41funny_pictures.json\u3002 \u8f93\u5165\u4f60\u60f3\u8981\u7684\u5185\u5bb9\u3002 \u8fd9\u91cc\u53ef\u4ee5\u8f93\u5165\u4e00\u4e9b\u6bd4\u8f83\u641e\u602a\u7684\u5185\u5bb9\uff0c\u6bd4\u5982\u6211\u8fd9\u91cc\u662f\u5173\u7fbd\u5927\u6218\u767d\u96ea\u516c\u4e3b\u3002 \u53ef\u4ee5\u5728\u6b64\u5904\u8bbe\u7f6e\u56fe\u7247\u7684\u5206\u8fa8\u7387\u548c\u56fe\u7247\u7684\u6570\u91cf\u3002\u5982\u679c\u60f3\u52a0\u5feb\u751f\u4ea7\u901f\u5ea6\uff0c\u53ef\u5c06batch_size\u8bbe\u7f6e\u4e3a1. \u7b49\u5f85\u56fe\u7247\u7684\u751f\u6210\u3002","title":"\u6587\u751f\u56fe\u529f\u80fd"},{"location":"#_16","text":"\u8bbf\u95ee\u6a21\u7248\uff0c\u6216\u81ea\u5df1\u5bfc\u5165\u5de5\u4f5c\u6d41\u4f7f\u7528\u3002","title":"\u56fe\u751f\u56fe\u529f\u80fd"},{"location":"#api","text":"","title":"API\u8c03\u7528"},{"location":"#api_1","text":"\u7aef\u70b9 \u65b9\u6cd5 \u529f\u80fd \u8bf4\u660e /queue GET \u83b7\u53d6\u961f\u5217\u72b6\u6001 \u67e5\u770b\u5f53\u524d\u4efb\u52a1\u961f\u5217 /prompt POST \u63d0\u4ea4\u5de5\u4f5c\u6d41 \u6267\u884c\u751f\u6210\u4efb\u52a1 /history/{prompt_id} GET \u83b7\u53d6\u6267\u884c\u5386\u53f2 \u67e5\u770b\u4efb\u52a1\u6267\u884c\u7ed3\u679c /upload/image POST \u4e0a\u4f20\u56fe\u7247 \u4e0a\u4f20\u8f93\u5165\u56fe\u7247\u6587\u4ef6 /view GET \u4e0b\u8f7d\u8f93\u51fa\u6587\u4ef6 \u83b7\u53d6\u751f\u6210\u7684\u7ed3\u679c\u6587\u4ef6 \u652f\u6301\u516c\u7f51\u6216\u8005\u79c1\u7f51\u7684API\u8c03\u7528\u3002 \u53ef\u53c2\u8003\u4e00\u4e0b\u4ee3\u7801\u5b9e\u73b0\u4e00\u4e2aAPI\u8c03\u7528\u7684\u811a\u672c\u3002 import requests import json import time def run_workflow_file(workflow_file, server=\"http://127.0.0.1:8188\"): \"\"\"\u8fd0\u884c\u672c\u5730\u5de5\u4f5c\u6d41JSON\u6587\u4ef6\"\"\" # \u52a0\u8f7d\u5de5\u4f5c\u6d41 with open(workflow_file, 'r', encoding='utf-8') as f: workflow = json.load(f) # \u63d0\u4ea4 response = requests.post(f\"{server}/prompt\", json={\"prompt\": workflow}) prompt_id = response.json()['prompt_id'] print(f\"\u4efb\u52a1\u63d0\u4ea4: {prompt_id}\") # \u7b49\u5f85\u5b8c\u6210 while True: response = requests.get(f\"{server}/history/{prompt_id}\") history = response.json() if prompt_id in history: break print(\"\u7b49\u5f85\u4e2d...\") time.sleep(3) # \u4e0b\u8f7d\u6240\u6709\u8f93\u51fa\u6587\u4ef6 outputs = history[prompt_id]['outputs'] for node_id, node_output in outputs.items(): # \u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u51fa for file_type in ['images', 'videos', 'gifs']: if file_type in node_output: for file_info in node_output[file_type]: filename = file_info['filename'] file_url = f\"{server}/view?filename={filename}&type=output\" response = requests.get(file_url) with open(filename, 'wb') as f: f.write(response.content) print(f\"\u5df2\u4e0b\u8f7d: {filename}\") # \u4f7f\u7528\u793a\u4f8b run_workflow_file(\"my_workflow.json\") \u5176\u4e2d\u672c\u5730\u5de5\u4f5c\u6d41\u91c7\u7528\u4e0b\u56fe\u63d0\u4f9b\u7684\u65b9\u5f0f\u6765\u83b7\u53d6\uff1a \u7531\u4e8eComfyui\u672a\u63d0\u4f9b\u5b98\u65b9\u7684API\u6587\u6863\uff0c\u6b64\u5904\u6839\u636e\u6587\u751f\u89c6\u9891\u548c\u56fe\u751f\u89c6\u9891\u63d0\u4f9b\u4e24\u4e2a\u5b8c\u6574\u7684\u793a\u4f8b\uff1a\u5173\u4e8e\u5982\u4f55\u4f7f\u7528API\u6765\u8c03\u7528\u5de5\u4f5c\u6d41\u8fdb\u884c\u6587\u751f\u56fe\u6216\u8005\u6587\u751f\u89c6\u9891\u7b49 \u8bbf\u95ee\uff1ahttps://github.com/aliyun-computenest/comfyui-acs/ \u627e\u5230demo\u6587\u4ef6\u5939","title":"API \u7aef\u70b9\u6982\u89c8"},{"location":"#api_2","text":"\u6253\u5f00text_to_video_workflow.json\u4e3a\u5b9a\u4e49\u7684\u5de5\u4f5c\u6d41\uff0c\u786e\u8ba4\u597d\u6a21\u578b\u3002\uff08\u91cc\u9762\u9ed8\u8ba4\u5b9a\u4e49\u7684\u6a21\u578b\u4e3a14B\u7684\u4e07\u76f82.1\u6587\u751f\u89c6\u9891\u6a21\u578b\uff09 \u786e\u8ba4\u597dPrompt\u548c\u751f\u6210\u7684\u5206\u8fa8\u7387\u7b49\u53c2\u6570 \u4fee\u6539\u4ee3\u7801\u4e2dserver\u670d\u52a1\u5730\u5740\uff0c\u7531127.0.0.1\u5230\u4f60\u7684\u5b9e\u9645\u670d\u52a1\u5730\u5740\u3002 \u672c\u5730\u6267\u884cpython text_to_video_example.py\uff0c\u7b49\u5f85\u89c6\u9891\u751f\u6210","title":"\u6587\u751f\u89c6\u9891API\u65b9\u5f0f"},{"location":"#api_3","text":"\u6253\u5f00image_to_video_workflow.json\u4e3a\u5b9a\u4e49\u7684\u5de5\u4f5c\u6d41\uff0c\u786e\u8ba4\u597d\u6a21\u578b\u3002\uff08\u91cc\u9762\u9ed8\u8ba4\u5b9a\u4e49\u7684\u6a21\u578b\u4e3a14B\u7684\u4e07\u76f82.1\u56fe\u751f\u89c6\u9891\u6a21\u578b\uff09 \u786e\u8ba4\u597dPrompt\u548c\u751f\u6210\u7684\u5206\u8fa8\u7387\u7b49\u53c2\u6570 \u4fee\u6539\u4ee3\u7801\u4e2dserver\u670d\u52a1\u5730\u5740\uff0c\u7531127.0.0.1\u5230\u4f60\u7684\u5b9e\u9645\u670d\u52a1\u5730\u5740\u3002 \u672c\u5730\u6267\u884cpython image_to_video_example.py\uff0c\u7b49\u5f85\u89c6\u9891\u751f\u6210","title":"\u56fe\u751f\u89c6\u9891API\u65b9\u5f0f"},{"location":"#_17","text":"\u9ed8\u8ba4\u8d26\u53f7\u548c\u5bc6\u7801\u4e3a: 1. \u8d26\u53f7\uff1aadmin 2. \u5bc6\u7801\uff1aadmin","title":"\u8d26\u53f7\u5bc6\u7801"},{"location":"#_18","text":"\u51fa\u73b0\u67d0\u4e2a\u8282\u70b9\u7c7b\u578b\u4e0d\u5b58\u5728\uff0c\u901a\u8fc7manager\u5b89\u88c5\u7f3a\u5c11\u7684\u8282\u70b9\uff0c\u5e76\u91cd\u542f\u3002","title":"\u5e38\u89c1\u95ee\u9898"},{"location":"index-en/","text":"ComfyUI Community Edition Disclaimer: This service is provided by a third party. We try our best to ensure its safety, accuracy and reliability, but we cannot guarantee that it is completely free from failures, interruptions, errors or attacks. Therefore, the company hereby declares that it makes no representations, warranties or commitments regarding the content, accuracy, completeness, reliability, suitability and timeliness of the Service and is not liable for any direct or indirect loss or damage arising from your use of the Service; for third-party websites, applications, products and services that you access through the Service, do not assume any responsibility for its content, accuracy, completeness, reliability, applicability and timeliness, and you shall bear the risks and responsibilities of the consequences of use; for any loss or damage arising from your use of this service, including but not limited to direct loss, indirect loss, loss of profits, loss of goodwill, loss of data or other economic losses, even if we have been advised in advance of the possibility of such loss or damage; we reserve the right to amend this statement from time to time, so please check this statement regularly before using the Service. If you have any questions or concerns about this Statement or the Service, please contact us. Overview ComfyUI is the most powerful open source, node-based, generative AI application for creating images, video, and audio content. Relying on cutting-edge open source models can achieve video and image generation. According to the official documentation, the ComfyUI has the following characteristics: Node/Graph/Flowchart interface for experimenting and creating complex stable diffusion workflows without writing any code. Full support for SD1.x, SD2.x and SDXL asynchronous queue system Multiple optimizations re-execute only those parts of the workflow that have changed between executions. Command line options: -- lowvram to make it run on GPUs with less than 3GB of memory (automatically enabled on GPUs with low memory) Can be used even without GPU: -- cpu (slow) Can load ckpt, safetensors, and diffusers models/checkpoints. Independent VAE and CLIP models. Embedding/Text Inversion Loras (regular, locon and loha) Hypernetwork Load the complete workflow from the generated PNG file (with seed Save/load workflow as Json file. The node interface can be used to create complex workflows, such as \"Hires fix\" or more advanced workflows. Regional Synthesis Inline using regular and Inline models. Control network and T2I adapter Upgrade models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc.) unCLIP model GLIGEN Model Merge Latent preview with TAESD Start up extremely fast. Works completely offline: nothing is downloaded. The configuration file sets the search path for the model. Prerequisites To deploy the ComfyUI Community Edition service instance, you need to access and create some Alibaba Cloud resources. Therefore, your account must contain permissions for the following resources. Note : This permission is required only when your account is a RAM account. Permission policy name Comment AliyunECSFullAccess Permissions for managing ECS instances AliyunVPCFullAccess Permissions to manage a VPC AliyunROSFullAccess Manage permissions for Resource Orchestration Service (ROS) AliyunCSFullAccess Manage permissions for Container Service (CS) AliyunComputeNestUserFullAccess Manage user-side permissions for the compute nest service (ComputeNest) AliyunOSSFullAccess Permissions to manage Network Object Storage Service (OSS) Billing Description ACS version fee The cost of this service on Alibaba Cloud is mainly related: * ACS Fees * Springboard machine ECS fee * Note: This ECS is used to deploy and manage K8S clusters. The/root directory stores the K8S Yaml resource files used for deployment. If you need to modify the parameters later, you can re-execute the apply kubectl after modifying them. If the deployment is completed, it can be released by itself if it is not needed. * OSS Fees Billing method: pay by volume (hour) or package year and month The estimated cost can be seen in real time when the instance is created. Community Edition Fee The cost of community edition deployment in computing nest mainly involves: Selected vCPU and Memory Specifications System disk type and capacity public network bandwidth Overall architecture Deployment process ACS version deployment Click Deployment Link . Fill in the parameters according to the interface prompt to see the corresponding RFQ details. After confirming the parameters, click Next: Confirm Order . Click Next: After confirming the order , you can also see the price preview, then click Deploy Now and wait for the deployment to complete. Wait for the deployment to complete before you can start using the service. ECS Community Edition Deployment Visit the calculation nest deployment link and fill in the deployment parameters as prompted Fill in the instance parameters , select the method and instance type you want to purchase. Note * * If you want to use the video function, in order to reduce the possibility of RAM memory explosion, please select a graphics card specification above A10 with a memory specification of more than 60G. Choose to create a new private network or directly use an existing private network according to your needs. Fill in the available area and network parameters Click Create Now and wait for the service instance deployment to complete After the service instance is deployed, click the instance ID to enter the details interface Access the URL of the service instance, where we use a secure proxy for direct access. Avoid exposing your data to the public network to be obtained by others Enter the ComfyUI use interface Parameter description Parameter group Parameter item Description Service Instance Service Instance Name The service instance name must be no more than 64 characters in length and must start with an English letter. It can contain numbers, English letters, dashes (-), and underscores (_). Region The region where the service instance is deployed Billing Type Billing type of the resource: Pay-As-You-Go and Subscription ECS instance configuration Instance type Available instance types in the zone Network Configuration Availability Zone The zone where the ECS instance is located VPC ID The VPC where the resource resides VSwitch ID VSwitch where the resource resides Built-in model description Overview of main models | Model name | Type | Parameter scale | Resolution | Quantization format | Introduction | | --------- | ------ | --------- | --------- | --------- | ------ | ------ | | Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors | Picture Video | 14B | 480P | FP8 E4M3FN | WanVideo 2.1 Picture Video Model, 14B Parameters, Support 480P Resolution Output, Use FP8 Quantization to Save Video | | Wan2_1-T2V-14B_fp8_e4m3fn.safetensors | Vincent Video | 14B | Standard | FP8 E4M3FN | WanVideo 2.1 Vincent Video Model, 14B Parameters, Generate Video Directly from Text, FP8 Quantized Version | | flux1-dev.safetensors | Image Generation | - | High Resolution | Standard | Flux. 1 Dev model, high-quality image generation model, support for high-resolution output, developer version | | wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors | Wensheng Video | 1.3B | Standard | FP8 E4M3FN | WanVideo 2.1 Lightweight Wensheng Video Model, 1.3B Parameters, Lower Display and Storage Requirements Compared with 14B Version, Suitable for Resource-Constrained Environment | | vace-1.3b.safetensors | Video Editing | 1.3B | Standard | Standard | VACE 1.3B video editing model, focusing on video content editing and processing, lightweight design, suitable for fast video editing tasks | Full Model Resource List \ud83d\udcca Model Categories Overview Category Directory Total Size Model Count Primary Function Diffusion Models '/diffusion_models' 53GB 6 models Core image/video generation Text Encoders '/text_encoders' 22GB 2 models Text understanding CLIP Models '/clip' 17GB 4 models Vision-language understanding Checkpoints '/checkpoints' 17GB 1 model Complete model checkpoints UNET Models '/unet' 14GB 1 model Neural network architecture VAE Models '/vae' 1.5GB 5 models Latent space processing CLIP Vision '/clip_vision' 2.4GB 1 model Visual understanding Face Restoration '/facerestore_models' 1.3GB 4 models Face enhancement Video Interpolation '/interpolation' 824MB 4 models Frame interpolation Content Safety '/nsfw_detector' 329MB 1 model Content moderation Upscaling '/upscale_models' 192MB 3 models Image super-resolution VAE Approximation '/vae_approx' 19MB 4 models Fast preview generation Text Embeddings '/embeddings' 260KB 2 models Negative prompts Configurations '/configs' 52KB 11 files Model configurations \ud83c\udfaf Diffusion Models ('/diffusion_models') - 53GB Model Name Size Type Parameters Function Best For 'Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors' 16GB Image\u2192Video 14B Animate static images Image animation 'Wan2_1-T2V-14B_fp8_e4m3fn.safetensors' 14GB Text\u2192Video 14B Generate videos from text Text-to-video 'flux1-dev.safetensors' 12GB Text\u2192Image - Experimental image generation Testing new features 'wan21_vace_1_3b.safetensors' 6.7GB Video Editing 1.3B Enhanced video editing Professional editing 'wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors' 1.4GB Text\u2192Video 1.3B Fast video generation Quick previews \ud83e\udde0 Text Encoders ('/text_encoders') - 22GB Model Name Size Format Precision Function Best For 'wan2.1/umt5-xxl-enc-bf16.safetensors' 11GB SafeTensors BF16 Multi-language text encoding High-quality generation 'wan2.1/models_t5_umt5-xxl-enc-bf16.pth' 11GB PyTorch BF16 T5-based text encoding PyTorch workflows \ud83c\udfa8 CLIP Models ('/clip') - 17GB Model Name Size Type Precision Function Best For 't5xxl_fp16.safetensors' 9.2GB T5 Text Encoder FP16 Advanced text understanding Complex prompts 'umt5_xxl_fp8_e4m3fn.safetensors' 6.3GB UMT5 Encoder FP8 Efficient text encoding Resource optimization 'wan2.1/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors' 1.2GB Multilingual CLIP FP16 Cross-language vision International content 'clip_l.safetensors' 235MB CLIP Language - Vision-language alignment Standard workflows \ud83d\udcbe Checkpoints ('/checkpoints') - 17GB Model Name Size Type Precision Function Best For 'flux1-schnell-fp8.safetensors' 17GB Fast Image Gen FP8 Rapid image generation Production workflows \ud83d\udd27 UNET Models ('/unet') - 14GB Model Name Size Type Quantization Function Best For 'Wan2.1_14B_VACE-Q6_K.gguf' 14GB Video Editing Q6_K Professional video editing High-quality editing \ud83d\udd04 VAE Models ('/vae') - 1.5GB Model Name Size Type Precision Function Best For 'AE .safetensors' 320MB Standard VAE - Basic latent processing General use 'vae-ft-mse-840000-ema-pruned.safetensors' 320MB Fine-tuned VAE - High-quality reconstruction Quality workflows 'diffusion_pytorch_model.safetensors' 320MB Standard VAE - Broad compatibility General compatibility 'wan2.1/Wan2_1_VAE_bf16.safetensors' 243MB Wan2.1 VAE BF16 Video-optimized processing Video generation 'wan21_vace_vae.safetensors' 243MB VACE VAE - Video editing processing Video editing \ud83d\udc41\ufe0f CLIP Vision Models ('/clip_vision') - 2.4GB Model Name Size Architecture Training Data Function Best For 'CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors' 2.4GB ViT-Huge-14 LAION-2B Visual understanding High-quality analysis \ud83c\udfac Video Interpolation Models ('/interpolation') - 824MB GIMM-VFI Directory ('/interpolation/gimm-vfi' & '/interpolation/GIMM-VFI_safetensors') Model Name Size Type Function Best For 'gimmvfi_f_arb_lpips_fp32.safetensors' 117MB Full VFI Model Complete frame interpolation Production workflows 'gimmvfi_r_arb_lpips_fp32.safetensors' 76MB Refinement Model Frame quality enhancement Quality improvement 'flowformer_sintel_fp32.safetensors' 62MB Motion Model Advanced motion understanding Complex motion 'raft-things_fp32.safetensors' 21MB Optical Flow Motion estimation Motion calculation \ud83d\udd0d Face Restoration Models ('/facerestore_models') - 1.3GB Model Name Size Type Function Best For 'codeformer-v0.1.0.pth' 360MB CodeFormer Advanced face enhancement Professional portraits 'GFPGANv1.4.pth' 333MB GFPGAN v1.4 Improved face restoration High-quality restoration 'GFPGANv1.3.pth' 333MB GFPGAN v1.3 Face restoration General face enhancement 'GPEN-BFR-512.onnx' 272MB GPEN (ONNX) Real-time face restoration Fast processing \u2b06\ufe0f Upscaling Models ('/upscale_models') - 192MB Model Name Size Scale Type Function Best For '8x_NMKD-Superscale_150000_G.pth' 64MB 8x NMKD Extreme upscaling Maximum resolution '4x_foolhardy_Remacri.pth' 64MB 4x Enhanced ESRGAN Sharp upscaling General upscaling '4x_NMKD-Siax_200k.pth' 64MB 4x NMKD Siax Alternative upscaling Artistic enhancement \ud83d\udeab Content Safety Models ('/nsfw_detector') - 329MB Model Name Size Architecture Function Best For 'vit-base-nsfw-detector/model.safetensors' 329MB ViT-Base Content moderation Safety filtering Additional Files: -'config.json'-Model configuration -'preprocessor_config.json'-Input preprocessing -'confusion_matrix.png'-Performance metrics \u26a1 VAE Approximation Models ('/vae_approx') - 19MB Model Name Size Target Function Best For 'taef1_decoder.pth' 4.8MB SD3/FLUX Fast preview for SD3/FLUX Modern models 'taesd3_decoder.pth' 4.8MB SD3 Fast preview for SD3 SD3 workflows 'taesdxl_decoder.pth' 4.7MB SDXL Fast preview for SDXL SDXL workflows 'taesd_decoder.pth' 4.7MB SD1.5 Fast preview for SD1.5 SD1.5 workflows How to upload your own model Find the deployed service instance in the computing nest console, switch Tab to the resource interface, find the resource whose product is the object storage OSS, and click Enter. Access the \"file list\", under the path/llm-model/model for all types of models. You can upload the model according to your own needs and restart the comfyui client. Model Download recommend to go to magic to download The model storage path is:/root/storage/models Use process This service already has two workflows built in that you can use directly. The plugins and models involved are also ready. Tusheng video or Wensheng video function Select the desired function in the figure below. It is recommended to choose only one to use to avoid bursting memory. Select the workflow sidebar according to the instructions in the figure, select wanx-21.json and open it. Select a sample picture here or choose your own local computer to upload. Fill in the description at the TextEncode. The upper part is what you want to generate, and the lower part is what you don't want to generate. The resolution and frame number of the picture can be set at the ImageClip Encode. This model can be set up to 720*720. Other parameters can refer to official website: https://comfyui-wiki.com/zh/interface/node-options\u6216\u4ee5\u4e0b\u6587\u6863:https://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/readme.md PS: If you use the vace model, you can use the workflow vace.json as a reference Wensheng diagram function Select the workflow funny_pictures.json in the workflow box. Enter what you want. Here you can enter some funny content, for example, I am Guan Yu vs. Snow White. The resolution of the picture and the number of pictures can be set here. If you want to speed up production, you can set the batch_size to 1. Wait for the image to be generated. Figure function Access the template, or import your own workflow. API call API Endpoint Overview | Endpoint | Method | Function | Description | | ------ | ------ | ------ | ------ | ------ | | '/queue' | GET | Get the queue status | View the current task queue | | '/prompt' | POST | Submit Workflow | Execute Build Task | | '/history/{prompt_id}' | GET | Obtain execution history | View task execution results | | '/upload/image' | POST | Upload an image | Upload an input image file | | '/view' | GET | Download the output file | Get the generated result file | Supports public or private network API calls. You can refer to the code to implement an API call script. '''python import requests import json import time def run_workflow_file(workflow_file, server=\"http://127.0.0.1:8188\"): \"\" \"Run Local Workflow JSON File\" \"\" Load workflow with open(workflow_file, 'r', encoding='utf-8') as f: workflow = json.load(f) Submitted response = requests.post(f\"{server}/prompt\", json={\"prompt\": workflow}) prompt_id = response.json()['prompt_id'] print(f \"Task submission: {prompt_id}\") Waiting for completion while True: response = requests.get(f\"{server}/history/{prompt_id}\") history = response.json() if prompt_id in history: break print(\"Waiting...\") time.sleep(3) Download all output files outputs = history[prompt_id]['outputs'] for node_id, node_output in outputs.items(): Handle different types of output for file_type in ['images', 'videos', 'gifs']: if file_type in node_output: for file_info in node_output[file_type]: filename = file_info['filename'] file_url = f\"{server}/view?filename={filename}&type=output\" response = requests.get(file_url) with open(filename, 'wb') as f: f.write(response.content) print(f \"Downloaded: {filename}\") Use Examples run_workflow_file(\"my_workflow.json\") ''' The local workflow is obtained by using the method provided in the following figure: Since the Comfyui does not provide official API documents, here are two complete examples based on Wen Sheng video and Wen Sheng video: on how to use API to call workflow for Wen Sheng diagram or Wen Sheng video, etc. Visit: https://github.com/aliyun-computenest/comfyui-acs/ Find the demo folder Wen Sheng Video API Mode Open the workflow defined for confirm the good model. (The default model defined inside is the 14B's Wanxiang 2.1 Wensheng video model) Confirm parameters such as Prompt and generated resolution Modify the server service address in the code from 127.0.0.1 to your actual service address. Local execution of python, waiting for video generation. Picture generation video API Open the workflow defined for confirm the good model. (The default model defined inside is the video model of 14B universal phase 2.1 map generation) Confirm parameters such as Prompt and generated resolution Modify the server service address in the code from 127.0.0.1 to your actual service address. Local execution of python, waiting for video generation. Account password The default account and password are: 1. Account number: admin 2. Password: admin Frequently Asked Questions If a node type does not exist, install the missing node through manager and restart.","title":"ComfyUI Community Edition"},{"location":"index-en/#comfyui-community-edition","text":"Disclaimer: This service is provided by a third party. We try our best to ensure its safety, accuracy and reliability, but we cannot guarantee that it is completely free from failures, interruptions, errors or attacks. Therefore, the company hereby declares that it makes no representations, warranties or commitments regarding the content, accuracy, completeness, reliability, suitability and timeliness of the Service and is not liable for any direct or indirect loss or damage arising from your use of the Service; for third-party websites, applications, products and services that you access through the Service, do not assume any responsibility for its content, accuracy, completeness, reliability, applicability and timeliness, and you shall bear the risks and responsibilities of the consequences of use; for any loss or damage arising from your use of this service, including but not limited to direct loss, indirect loss, loss of profits, loss of goodwill, loss of data or other economic losses, even if we have been advised in advance of the possibility of such loss or damage; we reserve the right to amend this statement from time to time, so please check this statement regularly before using the Service. If you have any questions or concerns about this Statement or the Service, please contact us.","title":"ComfyUI Community Edition"},{"location":"index-en/#overview","text":"ComfyUI is the most powerful open source, node-based, generative AI application for creating images, video, and audio content. Relying on cutting-edge open source models can achieve video and image generation. According to the official documentation, the ComfyUI has the following characteristics: Node/Graph/Flowchart interface for experimenting and creating complex stable diffusion workflows without writing any code. Full support for SD1.x, SD2.x and SDXL asynchronous queue system Multiple optimizations re-execute only those parts of the workflow that have changed between executions. Command line options: -- lowvram to make it run on GPUs with less than 3GB of memory (automatically enabled on GPUs with low memory) Can be used even without GPU: -- cpu (slow) Can load ckpt, safetensors, and diffusers models/checkpoints. Independent VAE and CLIP models. Embedding/Text Inversion Loras (regular, locon and loha) Hypernetwork Load the complete workflow from the generated PNG file (with seed Save/load workflow as Json file. The node interface can be used to create complex workflows, such as \"Hires fix\" or more advanced workflows. Regional Synthesis Inline using regular and Inline models. Control network and T2I adapter Upgrade models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc.) unCLIP model GLIGEN Model Merge Latent preview with TAESD Start up extremely fast. Works completely offline: nothing is downloaded. The configuration file sets the search path for the model.","title":"Overview"},{"location":"index-en/#prerequisites","text":"To deploy the ComfyUI Community Edition service instance, you need to access and create some Alibaba Cloud resources. Therefore, your account must contain permissions for the following resources. Note : This permission is required only when your account is a RAM account. Permission policy name Comment AliyunECSFullAccess Permissions for managing ECS instances AliyunVPCFullAccess Permissions to manage a VPC AliyunROSFullAccess Manage permissions for Resource Orchestration Service (ROS) AliyunCSFullAccess Manage permissions for Container Service (CS) AliyunComputeNestUserFullAccess Manage user-side permissions for the compute nest service (ComputeNest) AliyunOSSFullAccess Permissions to manage Network Object Storage Service (OSS)","title":"Prerequisites"},{"location":"index-en/#billing-description","text":"","title":"Billing Description"},{"location":"index-en/#acs-version-fee","text":"The cost of this service on Alibaba Cloud is mainly related: * ACS Fees * Springboard machine ECS fee * Note: This ECS is used to deploy and manage K8S clusters. The/root directory stores the K8S Yaml resource files used for deployment. If you need to modify the parameters later, you can re-execute the apply kubectl after modifying them. If the deployment is completed, it can be released by itself if it is not needed. * OSS Fees Billing method: pay by volume (hour) or package year and month The estimated cost can be seen in real time when the instance is created.","title":"ACS version fee"},{"location":"index-en/#community-edition-fee","text":"The cost of community edition deployment in computing nest mainly involves: Selected vCPU and Memory Specifications System disk type and capacity public network bandwidth","title":"Community Edition Fee"},{"location":"index-en/#overall-architecture","text":"","title":"Overall architecture"},{"location":"index-en/#deployment-process","text":"","title":"Deployment process"},{"location":"index-en/#acs-version-deployment","text":"Click Deployment Link . Fill in the parameters according to the interface prompt to see the corresponding RFQ details. After confirming the parameters, click Next: Confirm Order . Click Next: After confirming the order , you can also see the price preview, then click Deploy Now and wait for the deployment to complete. Wait for the deployment to complete before you can start using the service.","title":"ACS version deployment"},{"location":"index-en/#ecs-community-edition-deployment","text":"Visit the calculation nest deployment link and fill in the deployment parameters as prompted Fill in the instance parameters , select the method and instance type you want to purchase. Note * * If you want to use the video function, in order to reduce the possibility of RAM memory explosion, please select a graphics card specification above A10 with a memory specification of more than 60G. Choose to create a new private network or directly use an existing private network according to your needs. Fill in the available area and network parameters Click Create Now and wait for the service instance deployment to complete After the service instance is deployed, click the instance ID to enter the details interface Access the URL of the service instance, where we use a secure proxy for direct access. Avoid exposing your data to the public network to be obtained by others Enter the ComfyUI use interface","title":"ECS Community Edition Deployment"},{"location":"index-en/#parameter-description","text":"Parameter group Parameter item Description Service Instance Service Instance Name The service instance name must be no more than 64 characters in length and must start with an English letter. It can contain numbers, English letters, dashes (-), and underscores (_). Region The region where the service instance is deployed Billing Type Billing type of the resource: Pay-As-You-Go and Subscription ECS instance configuration Instance type Available instance types in the zone Network Configuration Availability Zone The zone where the ECS instance is located VPC ID The VPC where the resource resides VSwitch ID VSwitch where the resource resides","title":"Parameter description"},{"location":"index-en/#built-in-model-description","text":"","title":"Built-in model description"},{"location":"index-en/#overview-of-main-models","text":"| Model name | Type | Parameter scale | Resolution | Quantization format | Introduction | | --------- | ------ | --------- | --------- | --------- | ------ | ------ | | Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors | Picture Video | 14B | 480P | FP8 E4M3FN | WanVideo 2.1 Picture Video Model, 14B Parameters, Support 480P Resolution Output, Use FP8 Quantization to Save Video | | Wan2_1-T2V-14B_fp8_e4m3fn.safetensors | Vincent Video | 14B | Standard | FP8 E4M3FN | WanVideo 2.1 Vincent Video Model, 14B Parameters, Generate Video Directly from Text, FP8 Quantized Version | | flux1-dev.safetensors | Image Generation | - | High Resolution | Standard | Flux. 1 Dev model, high-quality image generation model, support for high-resolution output, developer version | | wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors | Wensheng Video | 1.3B | Standard | FP8 E4M3FN | WanVideo 2.1 Lightweight Wensheng Video Model, 1.3B Parameters, Lower Display and Storage Requirements Compared with 14B Version, Suitable for Resource-Constrained Environment | | vace-1.3b.safetensors | Video Editing | 1.3B | Standard | Standard | VACE 1.3B video editing model, focusing on video content editing and processing, lightweight design, suitable for fast video editing tasks |","title":"Overview of main models"},{"location":"index-en/#full-model-resource-list","text":"","title":"Full Model Resource List"},{"location":"index-en/#model-categories-overview","text":"Category Directory Total Size Model Count Primary Function Diffusion Models '/diffusion_models' 53GB 6 models Core image/video generation Text Encoders '/text_encoders' 22GB 2 models Text understanding CLIP Models '/clip' 17GB 4 models Vision-language understanding Checkpoints '/checkpoints' 17GB 1 model Complete model checkpoints UNET Models '/unet' 14GB 1 model Neural network architecture VAE Models '/vae' 1.5GB 5 models Latent space processing CLIP Vision '/clip_vision' 2.4GB 1 model Visual understanding Face Restoration '/facerestore_models' 1.3GB 4 models Face enhancement Video Interpolation '/interpolation' 824MB 4 models Frame interpolation Content Safety '/nsfw_detector' 329MB 1 model Content moderation Upscaling '/upscale_models' 192MB 3 models Image super-resolution VAE Approximation '/vae_approx' 19MB 4 models Fast preview generation Text Embeddings '/embeddings' 260KB 2 models Negative prompts Configurations '/configs' 52KB 11 files Model configurations","title":"\ud83d\udccaModel Categories Overview"},{"location":"index-en/#diffusion-models-diffusion_models-53gb","text":"Model Name Size Type Parameters Function Best For 'Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors' 16GB Image\u2192Video 14B Animate static images Image animation 'Wan2_1-T2V-14B_fp8_e4m3fn.safetensors' 14GB Text\u2192Video 14B Generate videos from text Text-to-video 'flux1-dev.safetensors' 12GB Text\u2192Image - Experimental image generation Testing new features 'wan21_vace_1_3b.safetensors' 6.7GB Video Editing 1.3B Enhanced video editing Professional editing 'wan2.1/Wan2_1-T2V-1_3B_fp8_e4m3fn.safetensors' 1.4GB Text\u2192Video 1.3B Fast video generation Quick previews","title":"\ud83c\udfafDiffusion Models ('/diffusion_models') - 53GB"},{"location":"index-en/#text-encoders-text_encoders-22gb","text":"Model Name Size Format Precision Function Best For 'wan2.1/umt5-xxl-enc-bf16.safetensors' 11GB SafeTensors BF16 Multi-language text encoding High-quality generation 'wan2.1/models_t5_umt5-xxl-enc-bf16.pth' 11GB PyTorch BF16 T5-based text encoding PyTorch workflows","title":"\ud83e\udde0Text Encoders ('/text_encoders') - 22GB"},{"location":"index-en/#clip-models-clip-17gb","text":"Model Name Size Type Precision Function Best For 't5xxl_fp16.safetensors' 9.2GB T5 Text Encoder FP16 Advanced text understanding Complex prompts 'umt5_xxl_fp8_e4m3fn.safetensors' 6.3GB UMT5 Encoder FP8 Efficient text encoding Resource optimization 'wan2.1/open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors' 1.2GB Multilingual CLIP FP16 Cross-language vision International content 'clip_l.safetensors' 235MB CLIP Language - Vision-language alignment Standard workflows","title":"\ud83c\udfa8CLIP Models ('/clip') - 17GB"},{"location":"index-en/#checkpoints-checkpoints-17gb","text":"Model Name Size Type Precision Function Best For 'flux1-schnell-fp8.safetensors' 17GB Fast Image Gen FP8 Rapid image generation Production workflows","title":"\ud83d\udcbeCheckpoints ('/checkpoints') - 17GB"},{"location":"index-en/#unet-models-unet-14gb","text":"Model Name Size Type Quantization Function Best For 'Wan2.1_14B_VACE-Q6_K.gguf' 14GB Video Editing Q6_K Professional video editing High-quality editing","title":"\ud83d\udd27UNET Models ('/unet') - 14GB"},{"location":"index-en/#vae-models-vae-15gb","text":"Model Name Size Type Precision Function Best For 'AE .safetensors' 320MB Standard VAE - Basic latent processing General use 'vae-ft-mse-840000-ema-pruned.safetensors' 320MB Fine-tuned VAE - High-quality reconstruction Quality workflows 'diffusion_pytorch_model.safetensors' 320MB Standard VAE - Broad compatibility General compatibility 'wan2.1/Wan2_1_VAE_bf16.safetensors' 243MB Wan2.1 VAE BF16 Video-optimized processing Video generation 'wan21_vace_vae.safetensors' 243MB VACE VAE - Video editing processing Video editing","title":"\ud83d\udd04VAE Models ('/vae') - 1.5GB"},{"location":"index-en/#clip-vision-models-clip_vision-24gb","text":"Model Name Size Architecture Training Data Function Best For 'CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors' 2.4GB ViT-Huge-14 LAION-2B Visual understanding High-quality analysis","title":"\ud83d\udc41\ufe0f CLIP Vision Models ('/clip_vision') - 2.4GB"},{"location":"index-en/#video-interpolation-models-interpolation-824mb","text":"","title":"\ud83c\udfacVideo Interpolation Models ('/interpolation') - 824MB"},{"location":"index-en/#gimm-vfi-directory-interpolationgimm-vfi-interpolationgimm-vfi_safetensors","text":"Model Name Size Type Function Best For 'gimmvfi_f_arb_lpips_fp32.safetensors' 117MB Full VFI Model Complete frame interpolation Production workflows 'gimmvfi_r_arb_lpips_fp32.safetensors' 76MB Refinement Model Frame quality enhancement Quality improvement 'flowformer_sintel_fp32.safetensors' 62MB Motion Model Advanced motion understanding Complex motion 'raft-things_fp32.safetensors' 21MB Optical Flow Motion estimation Motion calculation","title":"GIMM-VFI Directory ('/interpolation/gimm-vfi' &amp; '/interpolation/GIMM-VFI_safetensors')"},{"location":"index-en/#face-restoration-models-facerestore_models-13gb","text":"Model Name Size Type Function Best For 'codeformer-v0.1.0.pth' 360MB CodeFormer Advanced face enhancement Professional portraits 'GFPGANv1.4.pth' 333MB GFPGAN v1.4 Improved face restoration High-quality restoration 'GFPGANv1.3.pth' 333MB GFPGAN v1.3 Face restoration General face enhancement 'GPEN-BFR-512.onnx' 272MB GPEN (ONNX) Real-time face restoration Fast processing","title":"\ud83d\udd0dFace Restoration Models ('/facerestore_models') - 1.3GB"},{"location":"index-en/#upscaling-models-upscale_models-192mb","text":"Model Name Size Scale Type Function Best For '8x_NMKD-Superscale_150000_G.pth' 64MB 8x NMKD Extreme upscaling Maximum resolution '4x_foolhardy_Remacri.pth' 64MB 4x Enhanced ESRGAN Sharp upscaling General upscaling '4x_NMKD-Siax_200k.pth' 64MB 4x NMKD Siax Alternative upscaling Artistic enhancement","title":"\u2b06\ufe0f Upscaling Models ('/upscale_models') - 192MB"},{"location":"index-en/#content-safety-models-nsfw_detector-329mb","text":"Model Name Size Architecture Function Best For 'vit-base-nsfw-detector/model.safetensors' 329MB ViT-Base Content moderation Safety filtering Additional Files: -'config.json'-Model configuration -'preprocessor_config.json'-Input preprocessing -'confusion_matrix.png'-Performance metrics","title":"\ud83d\udeabContent Safety Models ('/nsfw_detector') - 329MB"},{"location":"index-en/#vae-approximation-models-vae_approx-19mb","text":"Model Name Size Target Function Best For 'taef1_decoder.pth' 4.8MB SD3/FLUX Fast preview for SD3/FLUX Modern models 'taesd3_decoder.pth' 4.8MB SD3 Fast preview for SD3 SD3 workflows 'taesdxl_decoder.pth' 4.7MB SDXL Fast preview for SDXL SDXL workflows 'taesd_decoder.pth' 4.7MB SD1.5 Fast preview for SD1.5 SD1.5 workflows","title":"\u26a1VAE Approximation Models ('/vae_approx') - 19MB"},{"location":"index-en/#how-to-upload-your-own-model","text":"Find the deployed service instance in the computing nest console, switch Tab to the resource interface, find the resource whose product is the object storage OSS, and click Enter. Access the \"file list\", under the path/llm-model/model for all types of models. You can upload the model according to your own needs and restart the comfyui client.","title":"How to upload your own model"},{"location":"index-en/#model-download","text":"recommend to go to magic to download The model storage path is:/root/storage/models","title":"Model Download"},{"location":"index-en/#use-process","text":"This service already has two workflows built in that you can use directly. The plugins and models involved are also ready.","title":"Use process"},{"location":"index-en/#tusheng-video-or-wensheng-video-function","text":"Select the desired function in the figure below. It is recommended to choose only one to use to avoid bursting memory. Select the workflow sidebar according to the instructions in the figure, select wanx-21.json and open it. Select a sample picture here or choose your own local computer to upload. Fill in the description at the TextEncode. The upper part is what you want to generate, and the lower part is what you don't want to generate. The resolution and frame number of the picture can be set at the ImageClip Encode. This model can be set up to 720*720. Other parameters can refer to official website: https://comfyui-wiki.com/zh/interface/node-options\u6216\u4ee5\u4e0b\u6587\u6863:https://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/readme.md PS: If you use the vace model, you can use the workflow vace.json as a reference","title":"Tusheng video or Wensheng video function"},{"location":"index-en/#wensheng-diagram-function","text":"Select the workflow funny_pictures.json in the workflow box. Enter what you want. Here you can enter some funny content, for example, I am Guan Yu vs. Snow White. The resolution of the picture and the number of pictures can be set here. If you want to speed up production, you can set the batch_size to 1. Wait for the image to be generated.","title":"Wensheng diagram function"},{"location":"index-en/#figure-function","text":"Access the template, or import your own workflow.","title":"Figure function"},{"location":"index-en/#api-call","text":"","title":"API call"},{"location":"index-en/#api-endpoint-overview","text":"| Endpoint | Method | Function | Description | | ------ | ------ | ------ | ------ | ------ | | '/queue' | GET | Get the queue status | View the current task queue | | '/prompt' | POST | Submit Workflow | Execute Build Task | | '/history/{prompt_id}' | GET | Obtain execution history | View task execution results | | '/upload/image' | POST | Upload an image | Upload an input image file | | '/view' | GET | Download the output file | Get the generated result file | Supports public or private network API calls. You can refer to the code to implement an API call script. '''python import requests import json import time def run_workflow_file(workflow_file, server=\"http://127.0.0.1:8188\"): \"\" \"Run Local Workflow JSON File\" \"\"","title":"API Endpoint Overview"},{"location":"index-en/#load-workflow","text":"with open(workflow_file, 'r', encoding='utf-8') as f: workflow = json.load(f)","title":"Load workflow"},{"location":"index-en/#submitted","text":"response = requests.post(f\"{server}/prompt\", json={\"prompt\": workflow}) prompt_id = response.json()['prompt_id'] print(f \"Task submission: {prompt_id}\") Waiting for completion while True: response = requests.get(f\"{server}/history/{prompt_id}\") history = response.json() if prompt_id in history: break print(\"Waiting...\") time.sleep(3)","title":"Submitted"},{"location":"index-en/#download-all-output-files","text":"outputs = history[prompt_id]['outputs'] for node_id, node_output in outputs.items():","title":"Download all output files"},{"location":"index-en/#handle-different-types-of-output","text":"for file_type in ['images', 'videos', 'gifs']: if file_type in node_output: for file_info in node_output[file_type]: filename = file_info['filename'] file_url = f\"{server}/view?filename={filename}&type=output\" response = requests.get(file_url) with open(filename, 'wb') as f: f.write(response.content) print(f \"Downloaded: {filename}\")","title":"Handle different types of output"},{"location":"index-en/#use-examples","text":"run_workflow_file(\"my_workflow.json\") ''' The local workflow is obtained by using the method provided in the following figure: Since the Comfyui does not provide official API documents, here are two complete examples based on Wen Sheng video and Wen Sheng video: on how to use API to call workflow for Wen Sheng diagram or Wen Sheng video, etc. Visit: https://github.com/aliyun-computenest/comfyui-acs/ Find the demo folder","title":"Use Examples"},{"location":"index-en/#wen-sheng-video-api-mode","text":"Open the workflow defined for confirm the good model. (The default model defined inside is the 14B's Wanxiang 2.1 Wensheng video model) Confirm parameters such as Prompt and generated resolution Modify the server service address in the code from 127.0.0.1 to your actual service address. Local execution of python, waiting for video generation.","title":"Wen Sheng Video API Mode"},{"location":"index-en/#picture-generation-video-api","text":"Open the workflow defined for confirm the good model. (The default model defined inside is the video model of 14B universal phase 2.1 map generation) Confirm parameters such as Prompt and generated resolution Modify the server service address in the code from 127.0.0.1 to your actual service address. Local execution of python, waiting for video generation.","title":"Picture generation video API"},{"location":"index-en/#account-password","text":"The default account and password are: 1. Account number: admin 2. Password: admin","title":"Account password"},{"location":"index-en/#frequently-asked-questions","text":"If a node type does not exist, install the missing node through manager and restart.","title":"Frequently Asked Questions"}]}